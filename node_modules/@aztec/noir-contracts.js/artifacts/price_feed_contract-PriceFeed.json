{
  "transpiled": true,
  "noir_version": "1.0.0-beta.4+0000000000000000000000000000000000000000",
  "name": "PriceFeed",
  "functions": [
    {
      "name": "get_price",
      "is_unconstrained": true,
      "custom_attributes": [
        "public",
        "view"
      ],
      "abi": {
        "parameters": [
          {
            "name": "asset_id",
            "type": {
              "kind": "field"
            },
            "visibility": "private"
          }
        ],
        "return_type": {
          "abi_type": {
            "kind": "struct",
            "path": "asset::Asset",
            "fields": [
              {
                "name": "price",
                "type": {
                  "kind": "integer",
                  "sign": "unsigned",
                  "width": 128
                }
              }
            ]
          },
          "visibility": "public"
        },
        "error_types": {
          "206160798890201757": {
            "error_kind": "string",
            "string": "Storage slot 0 not allowed. Storage slots must start from 1."
          },
          "1806607318379452689": {
            "error_kind": "string",
            "string": "Function get_price can only be called statically"
          },
          "5019202896831570965": {
            "error_kind": "string",
            "string": "attempt to add with overflow"
          },
          "14225679739041873922": {
            "error_kind": "string",
            "string": "Index out of bounds"
          },
          "17843811134343075018": {
            "error_kind": "string",
            "string": "Stack too deep"
          }
        }
      },
      "bytecode": "JwACBAEoAAABBIBJJwAABAMnAgIEAScCAwQAHxgAAwACgEcuCIBHAAElAAAASyUAAABoLgQAAYBIKAIAAgSASCcCAwQBOw0AAgADKACAQwQAAygAgEQBAAAoAIBFBAAAKACARgQAASYlAAACIh4CAAIJJwIDAAEKOAIDBCQCAAQAAACJJQAAAksnAgIAAC0IAQQnAgUEBAAQAQUBJwMEBAEAKAQCBS0MBQYtDgIGACgGAgYtDgIGACgGAgYtDgIGKwIABQAAAAAAAAAAAgAAAAAAAAAALQgBBicCBwQFABABBwEnAwYEAQAoBgIHLQwHCC0OAggAKAgCCC0OAggAKAgCCC0OAggAKAgCCC0OBQgtCAEFAAABAgEtDgQFLQgBBAAAAQIBLQ4GBC0IAQYAAAECAS4KgEUABi0IAQcAAAECAS4KgEQABycCCAQJLQgACS0MBQotDAQLLQwGDC0MBw0tDAMOABAACAAlAAACXS0EAAAnAgMECC0IAAgtDAUJLQwECi0MBgstDAcMLQwBDQAQAAMAJQAAAl0tBAAALQ0HAQsoAAGARAADJAIAAwAAAbsnAggEADwJAQgnAgEECC0IAAgtDAUJLQwECi0MBgstDAcMABAAAQAlAAADiy0EAAAtDQQBASgAAYBGAAQtDQQDCjgDAgELKAABgEQAAiQCAAIAAAIMJQAABJ4vDAADAAEcDAEDBhwMAwIAHAwCAQYmKACABAR4AA0AAACABIADJACAAwAAAkoqAQABBfeh86+lrdTKPAEBAiYqAQABBRkSW8jEoNkRPAEBAiYlAAACIi0NAwYtDQQHCygAB4BEAAgkAgAIAAACgycCCQQAPAkBCQsoAAaAQwAHJAIABwAAAxcjAAACmC0NAQYtDQIHLQ0DCC0NBAkNKAAIgEMACicCCwEBJAIACgAAAsIlAAAEsC4EAAaAAygAgAQEAAQlAAAEwi4IgAUACgAoCgILADgLCAwtDgUMASgACIBGAAUOOAgFBiQCAAYAAAMCJQAABVAtDgoBLQ4HAi0OBQMtDgkEIwAAA4onAgYEBy0IAActDAEILQwCCS0MAwotDAQLABAABgAlAAADiy0EAAAtDQEGLQ0CBy0NBAguBAAGgAMoAIAEBAAEJQAABMIuCIAFAAkAKAkCCgEoAAqARQALLQ4FCy0OCQEtDgcCLgqARgADLQ4IBCMAAAOKJiUAAAIiLgiARQAFIwAAA5sNKAAFgEMABiQCAAYAAAQLIwAAA7AtDQEFLQ0CBi0NAwctDQQILQ0GCQAoCQIJLQ4JBicCCQQELQgBCicCCwQFABABCwEnAwoEAQAoBgILJwIMBAQAKAoCDT8PAAsADS0OBQEtDgoCLQ4HAy0OCAQmLQ0DBgw4BQYHASgABYBGAAYkAgAHAAAEKSMAAASVLQ0BBy0NAggtDQMJLQ0ECgAoCAIMADgMBQ0tDQ0LACgHAg0AOA0FDi0NDgwAOAsMDS4EAAiAAygAgAQEAAUlAAAEwi4IgAUACwAoCwIMADgMBQ4tDg0OLQ4HAS0OCwItDgkDLQ4KBCMAAASVLQwGBSMAAAObKgEAAQUC3G4ngHYSnTwBAQImKgEAAQXFa8RaDhAAAjwBAQImLgGAA4AGCwCABgACgAckAIAHAAAE3SMAAAToLgCAA4AFIwAABU8uAAABgAUBAAABgAQAAQEAgAOABIAJLgCAA4AKLgCABYALCwCACoAJgAwkAIAMAAAFOy4BgAqACC4CgAiACwEAgAoAAoAKAQCACwACgAsjAAAFCigBgAUEAAEDAIAGAAKABiMAAAVPJioBAAEFRafKcRlB5BU8AQECJg==",
      "debug_symbols": "7Z3bbuM4DIbfJde5EHUgxb7KYjHoIR0ECNIibRdYFH33dbKxk6noakIFAxTizaCZ8i+pz5IoUY79vnhY3b39/LHePj69LG7+el9snu5vX9dP2+HT+8dycbdbbzbrnz/O/3vh9v+A44Pg5fl2u//88nq7e13cgE+Ay8Vq+3D4OeThjzyuN6vFDePHsjCnkNLRmgLBZIwgGLN3ozF7n8+N/14uAOJvBBTdeUAHGatkXucteJ2MJBkSHUXIcZIkiR04DKMDgDAZQ0qSdRqj8c5PtgFIuoQcp0vIfLL22QnWIfmjcQQ82TrJ1gPDGIZ3XLFOno/GKbhfbPcAozeAbQDRADYBTGAA2wBaD2wDiNYDGwFaD2wDSM4AtgGMBrANIBvAJoA5GMA2gNkANgFk28pVAfIEA9JngB5sCDcCtGpMG0BvQ7gRoPXANoDBemAjQOuBbQCjVWMaASYD2AQwWTWmEWA0gG0ArRrTBhBtK9cI0KoxbQDJFtJcQrGDohJKtgWvAMUWsQIUWxaUUDgalBKKpe8CSnCWkgUoVq8qodhJkATFekoJxU5sJChdZp9heTaGEc7iGKGELueUGpQu55QKlD5PQGpQutwQ1qB0uSGsQEk20QpQbKItoWCXi7caFOspJRSylCxA6bKaX4GSu7x5oAYlGpQSiu2SSyh93sReg2ITbQElOptoBSi2Sy6hgPUUAUqXKZmmx4l4+vQVqsusDwi7TOAXIQREN7YQKRcIfZeZ7aoIgw3kZoRdllGvijB2WXS9DCHR1ELiMiNHSyetCFOXu8frIrSM3IoQu9xvXBdhNIStCC2dtCIkW9Q0I7Re2Iow26KmGaEtaqoI2Y31QmBfIuzzaxbXRdg8F0LOowMfUwVhSjxu2TH7059mlhjieEcvne3uAeM+8uTCd40c4NtGzt81cl+ZKujslvGZyKcBDUDuFwdCMDmMkVNOlWelE07PUCPE/LXxEAef5qzk8dx839Lg/nBL/amliF8HH4nHuSvms+fNe45ifQ9oqu+F0+UPIf3f0tRLS2Mv1xTlc1FwfkyQQ8ouvtiOM68TqKnE3DesA6aqMsSiqozy8VBNJZ+IVFWsUcl1bwCcaEAuacjlDQjTEwWGH0tf8o6+ppIfRFBVoUYl3/xWVanaxUGhIgcqlUwjTUMXUqRCBV6lYo1q5rUbFZWcv6qqpFFFla840y6cVtopF19Ao+RVKtKoMGlU5FQqFQ25BlNTZRVDnhlfp51R8OX4YlSosnMqVVSpskY1MwPUVCoaHlQqla+gIh9U5IOKfJwhH+OkSlSqskaVkkaFTqVCjYpApWKNKmvycs6kUTGoVBpf7MV2URwXehSx0MjZ61Su4lT6kfvg1xo531U0eLlG7rMVjYIB8uUa+bCmsi/hmdxYUc3kxpqKNCpW+WKNL3DO62Q6b6DzBlkl8zpvMxmyJgtOJ0sXzzKDSB4ubpzP2Asixdy0D1nhCTXhycO5JiKFSH7+WgVERoWINZ5YRj4VGJjKbgTy0rgmUnmqTdWSCBR9D7zTiEghCl4jygqRXD6qiTSekqZNijXCUPrSXKeLVwkfw8d/bnfr27vN6vhS1se37f3ZO1pf/31efXpd6/Pu6X718LZb7V/cenpn6z5gH3jp0R2G3PBxGOHL4ZoeYtv/djjw8BgGr4Pn/wA=",
      "brillig_names": [
        "get_price"
      ]
    },
    {
      "name": "set_price",
      "is_unconstrained": true,
      "custom_attributes": [
        "public"
      ],
      "abi": {
        "parameters": [
          {
            "name": "asset_id",
            "type": {
              "kind": "field"
            },
            "visibility": "private"
          },
          {
            "name": "price",
            "type": {
              "kind": "integer",
              "sign": "unsigned",
              "width": 128
            },
            "visibility": "private"
          }
        ],
        "return_type": null,
        "error_types": {
          "206160798890201757": {
            "error_kind": "string",
            "string": "Storage slot 0 not allowed. Storage slots must start from 1."
          },
          "5019202896831570965": {
            "error_kind": "string",
            "string": "attempt to add with overflow"
          },
          "14225679739041873922": {
            "error_kind": "string",
            "string": "Index out of bounds"
          },
          "17843811134343075018": {
            "error_kind": "string",
            "string": "Stack too deep"
          }
        }
      },
      "bytecode": "JwACBAEoAAABBIBJJwAABAMnAgMEAicCBAQAHxgABAADgEcdAIBIgEgGLgiARwABLgiASAACJQAAAFIlAAAAbygCAAEEgEknAgIEADsNAAEAAigAgEMEAAMoAIBEAQAAKACARQQAACgAgEYEAAEmJQAAAggnAgMAAC0IAQQnAgUEBAAQAQUBJwMEBAEAKAQCBS0MBQYtDgMGACgGAgYtDgMGACgGAgYtDgMGKwIABQAAAAAAAAAAAgAAAAAAAAAALQgBBicCBwQFABABBwEnAwYEAQAoBgIHLQwHCC0OAwgAKAgCCC0OAwgAKAgCCC0OAwgAKAgCCC0OBQgtCAEFAAABAgEtDgQFLQgBBAAAAQIBLQ4GBC0IAQYAAAECAS4KgEUABi0IAQcAAAECAS4KgEQABycCCAABJwIJBAotCAAKLQwFCy0MBAwtDAYNLQwHDi0MCA8AEAAJACUAAAIxLQQAACcCCAQJLQgACS0MBQotDAQLLQwGDC0MBw0tDAEOABAACAAlAAACMS0EAAAtDQcBCygAAYBEAAgkAgAIAAABqycCCQQAPAkBCScCAQQILQgACC0MBQktDAQKLQwGCy0MBwwAEAABACUAAANfLQQAAC0NBAEBKAABgEYABS0NBQQKOAQDAQsoAAGARAADJAIAAwAAAfwlAAAEchwMAgEAMAwAAQAEJigAgAQEeAANAAAAgASAAyQAgAMAAAIwKgEAAQX3ofOvpa3UyjwBAQImJQAAAggtDQMGLQ0EBwsoAAeARAAIJAIACAAAAlcnAgkEADwJAQkLKAAGgEMAByQCAAcAAALrIwAAAmwtDQEGLQ0CBy0NAwgtDQQJDSgACIBDAAonAgsBASQCAAoAAAKWJQAABIQuBAAGgAMoAIAEBAAEJQAABJYuCIAFAAoAKAoCCwA4CwgMLQ4FDAEoAAiARgAFDjgIBQYkAgAGAAAC1iUAAAUkLQ4KAS0OBwItDgUDLQ4JBCMAAANeJwIGBActCAAHLQwBCC0MAgktDAMKLQwECwAQAAYAJQAAA18tBAAALQ0BBi0NAgctDQQILgQABoADKACABAQABCUAAASWLgiABQAJACgJAgoBKAAKgEUACy0OBQstDgkBLQ4HAi4KgEYAAy0OCAQjAAADXiYlAAACCC4IgEUABSMAAANvDSgABYBDAAYkAgAGAAAD3yMAAAOELQ0BBS0NAgYtDQMHLQ0ECC0NBgkAKAkCCS0OCQYnAgkEBC0IAQonAgsEBQAQAQsBJwMKBAEAKAYCCycCDAQEACgKAg0/DwALAA0tDgUBLQ4KAi0OBwMtDggEJi0NAwYMOAUGBwEoAAWARgAGJAIABwAAA/0jAAAEaS0NAQctDQIILQ0DCS0NBAoAKAgCDAA4DAUNLQ0NCwAoBwINADgNBQ4tDQ4MADgLDA0uBAAIgAMoAIAEBAAFJQAABJYuCIAFAAsAKAsCDAA4DAUOLQ4NDi0OBwEtDgsCLQ4JAy0OCgQjAAAEaS0MBgUjAAADbyoBAAEFAtxuJ4B2Ep08AQECJioBAAEFxWvEWg4QAAI8AQECJi4BgAOABgsAgAYAAoAHJACABwAABLEjAAAEvC4AgAOABSMAAAUjLgAAAYAFAQAAAYAEAAEBAIADgASACS4AgAOACi4AgAWACwsAgAqACYAMJACADAAABQ8uAYAKgAguAoAIgAsBAIAKAAKACgEAgAsAAoALIwAABN4oAYAFBAABAwCABgACgAYjAAAFIyYqAQABBUWnynEZQeQVPAEBAiY=",
      "debug_symbols": "7Z3dbmI5DMffhWsuYsf58LzKajWiLR0hIVrRdqVVNe++ocs5MI2ZCAeNVMU31TnFf5z8yLETn6/3xcP67u3H983u8ell8e2v98X26X71unnalb33n8vF3X6z3W5+fD//98Id/gDED8HL82p32H95Xe1fF98C0nKx3j2ULYLyBY+b7bpsl83KFFz0R1sA8LMxhCBZh3g0RoezrYck2CamcDROzCdrzE6w9gGPxgTxZOskWwSGqRnouGEdkCcY3v1i+/dyAQgGsA9gMIBdAL0zgH0AbQT2ASQbgZ0AbQR2AmQD2AUweAPYBzAbwC6AEQ1gH8BkALsAJlvKNQFyOhpHCBVAtkO4E6BVY7oAorNDuBOgjcA+gGAjsBOgjcA+gGjVmE6AZAD7AFo1pg+gt2pMJ0CrxvQBJFvKdQK0akwfwGATaa6h2ImiGkq0Ca8AhQxKDcWmBTWUZJNNAYql7xpKtpQsQLF6VQ3FzgRJUGykVFC8nbGRoAyZfTBPZ+fRn7VjggJDxpQWFBspNZQxr8lvQRmydNCCMuSZigaUMc8+tKBYoK2hkAVaAcqQ0/wGlDGr+S0olpJrKGNW81tQyKDUUIas5jegJFslC1AsJddQsgVaAYoFWgGKrZJrKGwjRYAyZEpOMDcjfbqv7DrrgpDckAn8KoQQo5t6GFOuEMKQme22CO1A7kWIQ5ZRb4twyKLrdQhTmnuYuMrI5C2ddCMccvV4U4RjPiHotgjJEPYitElNL8Jg6aQboU1qehGO+ayg2yK0SU0vwmSTmiZCdlO9EBgFhJaRexHm7lgIOU8OkEIDYQg8LdljRpqtmSWGcbrMOZ2t7iHS/y1PX7XlHL5oy4PzX7blcqiYNSFho+XkJlsolaVfHNTW2cN02GWPp0v0o/jVPvrp+C/b+exuZiYxDs0PooNAZ5HIh4++gv+zfcWMc18d/b6v2eUpLubS1wYYiG4GU5z7c/NDT+VpCDicVS5W94YHOfM2VSSqwM81SKCqBhnk+NpSsVOpgkrFsiqeyOeKRpQfEwR+vim/bOZaRSpV1qjk0mVTFTUqUvVLfuxwSyUvAFsqec1TIok7RZJUq7JGlYJGJV9Q0lRFjYpBpdL4Su5Cv+IphmeuVVmjkiN/S4WgUkWNyqtoeFKpVAzpwvF1mkd7rI6vFFClihpVdCoVqVRZo0oqGklFPqt8ZRV5VpFnFXm+QJ5oVoUq2mRHGpX82MmmKmpUiCpV0qjkd3M0VZq8nMmrVJpsnoPKVxL7lWia6CWKnzUsZ69TcYNDrjWk0OTrNfItvQ1NvF6DCgby/ZINDSvWJXwhN7ZUWaO6MMZbKpWvoPIVVL6iyldU+Uqq3yupfF3IjS2VZlXN8pz699FFXrGym8IYY6UBpwhJpe2g8ISa5slHcUMk3zTbEiUFCEKNSONJvmmP57oCpyCIokIUNZ5iK0JLoqQZeykqRNlrRFkhYtKI+HoRKCYGRaToEyimBgCKuUFxdO2I+Fl2/1ntN6u77fr4hs3Ht9392Qs3X/99Xn969+bz/ul+/fC2Xx/ewnl6AefBN3pYYsCPX6XslrCwLMw+2nb4NPjyaShei+f/AA==",
      "brillig_names": [
        "set_price"
      ]
    },
    {
      "name": "public_dispatch",
      "is_unconstrained": true,
      "custom_attributes": [
        "public"
      ],
      "abi": {
        "parameters": [
          {
            "name": "selector",
            "type": {
              "kind": "field"
            },
            "visibility": "private"
          }
        ],
        "return_type": null,
        "error_types": {
          "206160798890201757": {
            "error_kind": "string",
            "string": "Storage slot 0 not allowed. Storage slots must start from 1."
          },
          "1806607318379452689": {
            "error_kind": "string",
            "string": "Function get_price can only be called statically"
          },
          "2830029349304997821": {
            "error_kind": "fmtstring",
            "length": 27,
            "item_types": [
              {
                "kind": "field"
              }
            ]
          },
          "5019202896831570965": {
            "error_kind": "string",
            "string": "attempt to add with overflow"
          },
          "14225679739041873922": {
            "error_kind": "string",
            "string": "Index out of bounds"
          },
          "17843811134343075018": {
            "error_kind": "string",
            "string": "Stack too deep"
          }
        }
      },
      "bytecode": "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",
      "debug_symbols": "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",
      "brillig_names": [
        "public_dispatch"
      ]
    },
    {
      "name": "sync_notes",
      "is_unconstrained": true,
      "custom_attributes": [
        "aztec::macros::functions::utility"
      ],
      "abi": {
        "parameters": [],
        "return_type": null,
        "error_types": {
          "17843811134343075018": {
            "error_kind": "string",
            "string": "Stack too deep"
          }
        }
      },
      "bytecode": "H4sIAAAAAAAA/7WTPQ+CMBCGi2KUjzjgoD+jBAyM+LG4OLpXCkpUSAB3frqQXENtwKjAJU17FJ5736OVUB0SzDLqEAyyglmBecTtj8vhQY67hakIdfvku9i2lQZ/Peq3FGBKw/Ax4w/UfzwFzr6o+bwXVndWDo1b66g+H0P5Z/9vSP+LD5418GpAXnmew/oS5Nt74t+Oz8c5SNnXTR1EgnIxdK5CSd0lcZ4SP99QmgZZJhJGDWTUQlU56pVE8YG26fmRdgrSLEpikSZ/Sav6yu6lXLyr8eA57hCOizHTMAb+BDV3X+b2+feXkKuCJ+bT+1Nn6BAztEhI1oRS2yeGwK+CP38vlizs4eEFAAA=",
      "debug_symbols": "rZLLqoMwFEX/JeMM8vbEXymXEjWWQIgS9UIR/72xxCK1tBMnh5yw2CySPaPGVtPt6kLbDai8zMh3tRldF9I2LxhV0Xnvbtf9NSLroPzJD70J6zqMJo6opERQjpENzfNcsJTROm9RqdWCD3gBKsNAxAtV/AMqmcyolOSFUg7LH0ZUnCADvNhkpP4uI7jOqFBwkJFnyIDYZDR8l1FkexnF1EFGnSCjGcuw5vKHDJCMFuTtm5a0/pvoTOVtrlc7hXrXtvHe27fi9bGrbTNFu1Zw1740LxQw4yk2RT8A",
      "brillig_names": [
        "sync_notes"
      ]
    }
  ],
  "outputs": {
    "globals": {
      "storage": [
        {
          "fields": [
            {
              "name": "contract_name",
              "value": {
                "kind": "string",
                "value": "PriceFeed"
              }
            },
            {
              "name": "fields",
              "value": {
                "fields": [
                  {
                    "name": "assets",
                    "value": {
                      "fields": [
                        {
                          "name": "slot",
                          "value": {
                            "kind": "integer",
                            "sign": false,
                            "value": "0000000000000000000000000000000000000000000000000000000000000001"
                          }
                        }
                      ],
                      "kind": "struct"
                    }
                  }
                ],
                "kind": "struct"
              }
            }
          ],
          "kind": "struct"
        }
      ]
    },
    "structs": {
      "functions": [
        {
          "fields": [
            {
              "name": "parameters",
              "type": {
                "fields": [
                  {
                    "name": "asset_id",
                    "type": {
                      "kind": "field"
                    }
                  }
                ],
                "kind": "struct",
                "path": "PriceFeed::get_price_parameters"
              }
            },
            {
              "name": "return_type",
              "type": {
                "fields": [
                  {
                    "name": "price",
                    "type": {
                      "kind": "integer",
                      "sign": "unsigned",
                      "width": 128
                    }
                  }
                ],
                "kind": "struct",
                "path": "asset::Asset"
              }
            }
          ],
          "kind": "struct",
          "path": "PriceFeed::get_price_abi"
        },
        {
          "fields": [
            {
              "name": "parameters",
              "type": {
                "fields": [
                  {
                    "name": "asset_id",
                    "type": {
                      "kind": "field"
                    }
                  },
                  {
                    "name": "price",
                    "type": {
                      "kind": "integer",
                      "sign": "unsigned",
                      "width": 128
                    }
                  }
                ],
                "kind": "struct",
                "path": "PriceFeed::set_price_parameters"
              }
            }
          ],
          "kind": "struct",
          "path": "PriceFeed::set_price_abi"
        }
      ]
    }
  },
  "file_map": {
    "138": {
      "path": "/home/aztec-dev/aztec-packages/noir-projects/aztec-nr/aztec/src/oracle/execution.nr",
      "source": "use dep::protocol_types::address::AztecAddress;\n\n#[oracle(getContractAddress)]\nunconstrained fn get_contract_address_oracle() -> AztecAddress {}\n\n#[oracle(getBlockNumber)]\nunconstrained fn get_block_number_oracle() -> u32 {}\n\n#[oracle(getChainId)]\nunconstrained fn get_chain_id_oracle() -> Field {}\n\n#[oracle(getVersion)]\nunconstrained fn get_version_oracle() -> Field {}\n\npub unconstrained fn get_contract_address() -> AztecAddress {\n    get_contract_address_oracle()\n}\n\npub unconstrained fn get_block_number() -> u32 {\n    get_block_number_oracle()\n}\n\npub unconstrained fn get_chain_id() -> Field {\n    get_chain_id_oracle()\n}\n\npub unconstrained fn get_version() -> Field {\n    get_version_oracle()\n}\n"
    },
    "155": {
      "path": "/home/aztec-dev/aztec-packages/noir-projects/aztec-nr/aztec/src/state_vars/map.nr",
      "source": "use crate::state_vars::storage::Storage;\nuse dep::protocol_types::{storage::map::derive_storage_slot_in_map, traits::{Packable, ToField}};\n\n// docs:start:map\npub struct Map<K, V, Context> {\n    context: Context,\n    storage_slot: Field,\n    state_var_constructor: fn(Context, Field) -> V,\n}\n// docs:end:map\n\nimpl<K, T, Context, let N: u32> Storage<N> for Map<K, T, Context>\nwhere\n    T: Packable<N>,\n{\n    fn get_storage_slot(self) -> Field {\n        self.storage_slot\n    }\n}\n\nimpl<K, V, Context> Map<K, V, Context> {\n    // docs:start:new\n    pub fn new(\n        context: Context,\n        storage_slot: Field,\n        state_var_constructor: fn(Context, Field) -> V,\n    ) -> Self {\n        assert(storage_slot != 0, \"Storage slot 0 not allowed. Storage slots must start from 1.\");\n        Map { context, storage_slot, state_var_constructor }\n    }\n    // docs:end:new\n\n    // docs:start:at\n    pub fn at(self, key: K) -> V\n    where\n        K: ToField,\n    {\n        // TODO(#1204): use a generator index for the storage slot\n        let derived_storage_slot = derive_storage_slot_in_map(self.storage_slot, key);\n\n        let state_var_constructor = self.state_var_constructor;\n        state_var_constructor(self.context, derived_storage_slot)\n    }\n    // docs:end:at\n}\n"
    },
    "164": {
      "path": "/home/aztec-dev/aztec-packages/noir-projects/aztec-nr/aztec/src/state_vars/public_mutable.nr",
      "source": "use crate::context::{PublicContext, UtilityContext};\nuse crate::state_vars::storage::Storage;\nuse dep::protocol_types::traits::Packable;\n\n// docs:start:public_mutable_struct\npub struct PublicMutable<T, Context> {\n    context: Context,\n    storage_slot: Field,\n}\n// docs:end:public_mutable_struct\n\nimpl<T, Context, let N: u32> Storage<N> for PublicMutable<T, Context>\nwhere\n    T: Packable<N>,\n{\n    fn get_storage_slot(self) -> Field {\n        self.storage_slot\n    }\n}\n\nimpl<T, Context> PublicMutable<T, Context> {\n    // docs:start:public_mutable_struct_new\n    pub fn new(\n        // Note: Passing the contexts to new(...) just to have an interface compatible with a Map.\n        context: Context,\n        storage_slot: Field,\n    ) -> Self {\n        assert(storage_slot != 0, \"Storage slot 0 not allowed. Storage slots must start from 1.\");\n        PublicMutable { context, storage_slot }\n    }\n    // docs:end:public_mutable_struct_new\n}\n\nimpl<T> PublicMutable<T, &mut PublicContext> {\n    // docs:start:public_mutable_struct_read\n    pub fn read<let T_PACKED_LEN: u32>(self) -> T\n    where\n        T: Packable<T_PACKED_LEN>,\n    {\n        self.context.storage_read(self.storage_slot)\n    }\n    // docs:end:public_mutable_struct_read\n\n    // docs:start:public_mutable_struct_write\n    pub fn write<let T_PACKED_LEN: u32>(self, value: T)\n    where\n        T: Packable<T_PACKED_LEN>,\n    {\n        self.context.storage_write(self.storage_slot, value);\n    }\n    // docs:end:public_mutable_struct_write\n}\n\nimpl<T> PublicMutable<T, UtilityContext> {\n    pub unconstrained fn read<let T_PACKED_LEN: u32>(self) -> T\n    where\n        T: Packable<T_PACKED_LEN>,\n    {\n        self.context.storage_read(self.storage_slot)\n    }\n}\n"
    },
    "200": {
      "path": "/home/aztec-dev/nargo/github.com/noir-lang/poseidon/v0.1.0/src/poseidon2.nr",
      "source": "use std::default::Default;\nuse std::hash::Hasher;\n\ncomptime global RATE: u32 = 3;\n\npub struct Poseidon2 {\n    cache: [Field; 3],\n    state: [Field; 4],\n    cache_size: u32,\n    squeeze_mode: bool, // 0 => absorb, 1 => squeeze\n}\n\nimpl Poseidon2 {\n    #[no_predicates]\n    pub fn hash<let N: u32>(input: [Field; N], message_size: u32) -> Field {\n        Poseidon2::hash_internal(input, message_size, message_size != N)\n    }\n\n    pub(crate) fn new(iv: Field) -> Poseidon2 {\n        let mut result =\n            Poseidon2 { cache: [0; 3], state: [0; 4], cache_size: 0, squeeze_mode: false };\n        result.state[RATE] = iv;\n        result\n    }\n\n    fn perform_duplex(&mut self) {\n        // add the cache into sponge state\n        for i in 0..RATE {\n            // We effectively zero-pad the cache by only adding to the state\n            // cache that is less than the specified `cache_size`\n            if i < self.cache_size {\n                self.state[i] += self.cache[i];\n            }\n        }\n        self.state = crate::poseidon2_permutation(self.state, 4);\n    }\n\n    fn absorb(&mut self, input: Field) {\n        assert(!self.squeeze_mode);\n        if self.cache_size == RATE {\n            // If we're absorbing, and the cache is full, apply the sponge permutation to compress the cache\n            self.perform_duplex();\n            self.cache[0] = input;\n            self.cache_size = 1;\n        } else {\n            // If we're absorbing, and the cache is not full, add the input into the cache\n            self.cache[self.cache_size] = input;\n            self.cache_size += 1;\n        }\n    }\n\n    fn squeeze(&mut self) -> Field {\n        assert(!self.squeeze_mode);\n        // If we're in absorb mode, apply sponge permutation to compress the cache.\n        self.perform_duplex();\n        self.squeeze_mode = true;\n\n        // Pop one item off the top of the permutation and return it.\n        self.state[0]\n    }\n\n    fn hash_internal<let N: u32>(\n        input: [Field; N],\n        in_len: u32,\n        is_variable_length: bool,\n    ) -> Field {\n        let two_pow_64 = 18446744073709551616;\n        let iv: Field = (in_len as Field) * two_pow_64;\n        let mut sponge = Poseidon2::new(iv);\n        for i in 0..input.len() {\n            if i < in_len {\n                sponge.absorb(input[i]);\n            }\n        }\n\n        // In the case where the hash preimage is variable-length, we append `1` to the end of the input, to distinguish\n        // from fixed-length hashes. (the combination of this additional field element + the hash IV ensures\n        // fixed-length and variable-length hashes do not collide)\n        if is_variable_length {\n            sponge.absorb(1);\n        }\n        sponge.squeeze()\n    }\n}\n\npub struct Poseidon2Hasher {\n    _state: [Field],\n}\n\nimpl Hasher for Poseidon2Hasher {\n    fn finish(self) -> Field {\n        let iv: Field = (self._state.len() as Field) * 18446744073709551616; // iv = (self._state.len() << 64)\n        let mut sponge = Poseidon2::new(iv);\n        for i in 0..self._state.len() {\n            sponge.absorb(self._state[i]);\n        }\n        sponge.squeeze()\n    }\n\n    fn write(&mut self, input: Field) {\n        self._state = self._state.push_back(input);\n    }\n}\n\nimpl Default for Poseidon2Hasher {\n    fn default() -> Self {\n        Poseidon2Hasher { _state: &[] }\n    }\n}\n"
    },
    "280": {
      "path": "/home/aztec-dev/aztec-packages/noir-projects/noir-protocol-circuits/crates/types/src/hash.nr",
      "source": "use crate::{\n    abis::{\n        contract_class_function_leaf_preimage::ContractClassFunctionLeafPreimage,\n        contract_class_log::ContractClassLog,\n        function_selector::FunctionSelector,\n        note_hash::ScopedNoteHash,\n        nullifier::ScopedNullifier,\n        private_log::{PrivateLog, PrivateLogData},\n        side_effect::{OrderedValue, scoped::Scoped},\n    },\n    address::{AztecAddress, EthAddress},\n    constants::{\n        FUNCTION_TREE_HEIGHT, GENERATOR_INDEX__NOTE_HASH_NONCE, GENERATOR_INDEX__OUTER_NULLIFIER,\n        GENERATOR_INDEX__SILOED_NOTE_HASH, GENERATOR_INDEX__UNIQUE_NOTE_HASH, TWO_POW_64,\n    },\n    merkle_tree::root::root_from_sibling_path,\n    messaging::l2_to_l1_message::{L2ToL1Message, ScopedL2ToL1Message},\n    poseidon2::Poseidon2Sponge,\n    traits::{FromField, Hash, ToField},\n    utils::{\n        arrays::{array_concat, unsafe_padded_array_length},\n        field::{field_from_bytes, field_from_bytes_32_trunc},\n    },\n};\n\npub fn sha256_to_field<let N: u32>(bytes_to_hash: [u8; N]) -> Field {\n    let sha256_hashed = sha256::digest(bytes_to_hash);\n    let hash_in_a_field = field_from_bytes_32_trunc(sha256_hashed);\n\n    hash_in_a_field\n}\n\npub fn private_functions_root_from_siblings(\n    selector: FunctionSelector,\n    vk_hash: Field,\n    function_leaf_index: Field,\n    function_leaf_sibling_path: [Field; FUNCTION_TREE_HEIGHT],\n) -> Field {\n    let function_leaf_preimage = ContractClassFunctionLeafPreimage { selector, vk_hash };\n    let function_leaf = function_leaf_preimage.hash();\n    root_from_sibling_path(\n        function_leaf,\n        function_leaf_index,\n        function_leaf_sibling_path,\n    )\n}\n\npub fn compute_note_hash_nonce(first_nullifier_in_tx: Field, note_index_in_tx: u32) -> Field {\n    // Hashing the first nullifier with note index in tx is guaranteed to be unique (because all nullifiers are also\n    // unique).\n    poseidon2_hash_with_separator(\n        [first_nullifier_in_tx, note_index_in_tx as Field],\n        GENERATOR_INDEX__NOTE_HASH_NONCE,\n    )\n}\n\npub fn compute_unique_note_hash(nonce: Field, siloed_note_hash: Field) -> Field {\n    let inputs = [nonce, siloed_note_hash];\n    poseidon2_hash_with_separator(inputs, GENERATOR_INDEX__UNIQUE_NOTE_HASH)\n}\n\npub fn compute_siloed_note_hash(app: AztecAddress, note_hash: Field) -> Field {\n    poseidon2_hash_with_separator(\n        [app.to_field(), note_hash],\n        GENERATOR_INDEX__SILOED_NOTE_HASH,\n    )\n}\n\n/// Computes unique note hashes from siloed note hashes\npub fn compute_unique_siloed_note_hash(\n    siloed_note_hash: Field,\n    first_nullifier: Field,\n    note_index_in_tx: u32,\n) -> Field {\n    if siloed_note_hash == 0 {\n        0\n    } else {\n        let nonce = compute_note_hash_nonce(first_nullifier, note_index_in_tx);\n        compute_unique_note_hash(nonce, siloed_note_hash)\n    }\n}\n\n/// Siloing in the context of Aztec refers to the process of hashing a note hash with a contract address (this way\n/// the note hash is scoped to a specific contract). This is used to prevent intermingling of notes between contracts.\npub fn silo_note_hash(note_hash: ScopedNoteHash) -> Field {\n    if note_hash.contract_address.is_zero() {\n        0\n    } else {\n        compute_siloed_note_hash(note_hash.contract_address, note_hash.value())\n    }\n}\n\npub fn compute_siloed_nullifier(app: AztecAddress, nullifier: Field) -> Field {\n    poseidon2_hash_with_separator(\n        [app.to_field(), nullifier],\n        GENERATOR_INDEX__OUTER_NULLIFIER,\n    )\n}\n\npub fn silo_nullifier(nullifier: ScopedNullifier) -> Field {\n    if nullifier.contract_address.is_zero() {\n        nullifier.value() // Return value instead of 0 because the first nullifier's contract address is zero.\n    } else {\n        compute_siloed_nullifier(nullifier.contract_address, nullifier.value())\n    }\n}\n\npub fn compute_siloed_private_log_field(contract_address: AztecAddress, field: Field) -> Field {\n    poseidon2_hash([contract_address.to_field(), field])\n}\n\npub fn silo_private_log(private_log: Scoped<PrivateLogData>) -> PrivateLog {\n    if private_log.contract_address.is_zero() {\n        private_log.inner.log\n    } else {\n        let mut fields = private_log.inner.log.fields;\n        fields[0] = compute_siloed_private_log_field(private_log.contract_address, fields[0]);\n        PrivateLog { fields }\n    }\n}\n\nfn compute_siloed_contract_class_log_field(\n    contract_address: AztecAddress,\n    first_field: Field,\n) -> Field {\n    poseidon2_hash([contract_address.to_field(), first_field])\n}\n\npub fn silo_contract_class_log(contract_class_log: ContractClassLog) -> ContractClassLog {\n    if contract_class_log.contract_address.is_zero() {\n        contract_class_log\n    } else {\n        let mut log = contract_class_log;\n        log.log.fields[0] = compute_siloed_contract_class_log_field(\n            contract_class_log.contract_address,\n            log.log.fields[0],\n        );\n        log\n    }\n}\n\npub fn compute_contract_class_log_hash(contract_class_log: ContractClassLog) -> Field {\n    let array = contract_class_log.log.fields;\n    // Safety: The below length is constrained in the base rollup.\n    let length = unsafe { unsafe_padded_array_length(array) };\n    if length == 0 {\n        0\n    } else {\n        poseidon2_hash(array)\n    }\n}\n\npub fn merkle_hash(left: Field, right: Field) -> Field {\n    poseidon2_hash([left, right])\n}\n\npub fn compute_l2_to_l1_hash(\n    contract_address: AztecAddress,\n    recipient: EthAddress,\n    content: Field,\n    rollup_version_id: Field,\n    chain_id: Field,\n) -> Field {\n    let mut bytes: [u8; 160] = std::mem::zeroed();\n\n    let inputs =\n        [contract_address.to_field(), rollup_version_id, recipient.to_field(), chain_id, content];\n    for i in 0..5 {\n        // TODO are bytes be in fr.to_buffer() ?\n        let item_bytes: [u8; 32] = inputs[i].to_be_bytes();\n        for j in 0..32 {\n            bytes[32 * i + j] = item_bytes[j];\n        }\n    }\n\n    sha256_to_field(bytes)\n}\n\npub fn silo_l2_to_l1_message(\n    msg: ScopedL2ToL1Message,\n    rollup_version_id: Field,\n    chain_id: Field,\n) -> Field {\n    if msg.contract_address.is_zero() {\n        0\n    } else {\n        compute_l2_to_l1_hash(\n            msg.contract_address,\n            msg.message.recipient,\n            msg.message.content,\n            rollup_version_id,\n            chain_id,\n        )\n    }\n}\n\n// Computes sha256 hash of 2 input hashes.\n//\n// NB: This method now takes in two 31 byte fields - it assumes that any input\n// is the result of a sha_to_field hash and => is truncated\n//\n// TODO(Jan and David): This is used for the encrypted_log hashes.\n// Can we check to see if we can just use hash_to_field or pedersen_compress here?\n//\npub fn accumulate_sha256(input: [Field; 2]) -> Field {\n    // This is a note about the cpp code, since it takes an array of Fields\n    // instead of a u128.\n    // 4 Field elements when converted to bytes will usually\n    // occupy 4 * 32 = 128 bytes.\n    // However, this function is making the assumption that each Field\n    // only occupies 128 bits.\n    //\n    // TODO(David): This does not seem to be getting guaranteed anywhere in the code?\n    // Concatentate two fields into 32x2 = 64 bytes\n    // accumulate_sha256 assumes that the inputs are pre-truncated 31 byte numbers\n    let mut hash_input_flattened = [0; 64];\n    for offset in 0..input.len() {\n        let input_as_bytes: [u8; 32] = input[offset].to_be_bytes();\n        for byte_index in 0..32 {\n            hash_input_flattened[offset * 32 + byte_index] = input_as_bytes[byte_index];\n        }\n    }\n\n    sha256_to_field(hash_input_flattened)\n}\n\npub fn verification_key_hash<let N: u32>(key: [Field; N]) -> Field {\n    crate::hash::poseidon2_hash(key)\n}\n\n#[inline_always]\npub fn pedersen_hash<let N: u32>(inputs: [Field; N], hash_index: u32) -> Field {\n    std::hash::pedersen_hash_with_separator(inputs, hash_index)\n}\n\npub fn poseidon2_hash<let N: u32>(inputs: [Field; N]) -> Field {\n    poseidon::poseidon2::Poseidon2::hash(inputs, N)\n}\n\n#[no_predicates]\npub fn poseidon2_hash_with_separator<let N: u32, T>(inputs: [Field; N], separator: T) -> Field\nwhere\n    T: ToField,\n{\n    let inputs_with_separator = array_concat([separator.to_field()], inputs);\n    poseidon2_hash(inputs_with_separator)\n}\n\n// Performs a fixed length hash with a subarray of the given input.\n// Useful for SpongeBlob in which we aborb M things and want to check it vs a hash of M elts of an N-len array.\n// Using stdlib poseidon, this will always absorb an extra 1 as a 'variable' hash, and not match spongeblob.squeeze()\n// or any ts implementation. Also checks that any remaining elts not hashed are empty.\n#[no_predicates]\npub fn poseidon2_hash_subarray<let N: u32>(input: [Field; N], in_len: u32) -> Field {\n    let mut sponge = poseidon2_absorb_chunks(input, in_len, false);\n    sponge.squeeze()\n}\n\n// NB the below is the same as poseidon::poseidon2::Poseidon2::hash(), but replacing a range check with a bit check,\n// and absorbing in chunks of 3 below.\n#[no_predicates]\npub fn poseidon2_cheaper_variable_hash<let N: u32>(input: [Field; N], in_len: u32) -> Field {\n    let mut sponge = poseidon2_absorb_chunks(input, in_len, true);\n    // In the case where the hash preimage is variable-length, we append `1` to the end of the input, to distinguish\n    // from fixed-length hashes. (the combination of this additional field element + the hash IV ensures\n    // fixed-length and variable-length hashes do not collide)\n    if in_len != N {\n        sponge.absorb(1);\n    }\n    sponge.squeeze()\n}\n\n// The below fn reduces gates of a conditional poseidon2 hash by approx 3x (thank you ~* Giant Brain Dev @IlyasRidhuan *~ for the idea)\n// Why? Because when we call stdlib poseidon, we call absorb for each item. When absorbing is conditional, it seems the compiler does not know\n// what cache_size will be when calling absorb, so it assigns the permutation gates for /each i/ rather than /every 3rd i/, which is actually required.\n// The below code forces the compiler to:\n//  - absorb normally up to 2 times to set cache_size to 1\n//  - absorb in chunks of 3 to ensure perm. only happens every 3rd absorb\n//  - absorb normally up to 2 times to add any remaining values to the hash\n// In fixed len hashes, the compiler is able to tell that it will only need to perform the permutation every 3 absorbs.\n// NB: it also replaces unnecessary range checks (i < thing) with a bit check (&= i != thing), which alone reduces the gates of a var. hash by half.\n\n#[no_predicates]\nfn poseidon2_absorb_chunks<let N: u32>(\n    input: [Field; N],\n    in_len: u32,\n    variable: bool,\n) -> Poseidon2Sponge {\n    let iv: Field = (in_len as Field) * TWO_POW_64;\n    let mut sponge = Poseidon2Sponge::new(iv);\n    // Even though shift is always 1 here, if we input in_len = 0 we get an underflow\n    // since we cannot isolate computation branches. The below is just to avoid that.\n    let shift = if in_len == 0 { 0 } else { 1 };\n    if in_len != 0 {\n        // cache_size = 0, init absorb\n        sponge.cache[0] = input[0];\n        sponge.cache_size = 1;\n        // shift = num elts already added to make cache_size 1 = 1 for a fresh sponge\n        // M = max_chunks = (N - 1 - (N - 1) % 3) / 3: (must be written as a fn of N to compile)\n        // max_remainder = (N - 1) % 3;\n        // max_chunks = (N - 1 - max_remainder) / 3;\n        sponge = poseidon2_absorb_chunks_loop::<N, (N - 1 - (N - 1) % 3) / 3>(\n            sponge,\n            input,\n            in_len,\n            variable,\n            shift,\n        );\n    }\n    sponge\n}\n\n// NB: If it's not required to check that the non-absorbed elts of 'input' are 0s, set skip_0_check=true\n#[no_predicates]\npub fn poseidon2_absorb_chunks_existing_sponge<let N: u32>(\n    in_sponge: Poseidon2Sponge,\n    input: [Field; N],\n    in_len: u32,\n    skip_0_check: bool,\n) -> Poseidon2Sponge {\n    let mut sponge = in_sponge;\n    // 'shift' is to account for already added inputs\n    let mut shift = 0;\n    // 'stop' is to avoid an underflow when inputting in_len = 0\n    let mut stop = false;\n    for i in 0..3 {\n        if shift == in_len {\n            stop = true;\n        }\n        if (sponge.cache_size != 1) & (!stop) {\n            sponge.absorb(input[i]);\n            shift += 1;\n        }\n    }\n    sponge = if stop {\n        sponge\n    } else {\n        // max_chunks = (N - (N % 3)) / 3;\n        poseidon2_absorb_chunks_loop::<N, (N - (N % 3)) / 3>(\n            sponge,\n            input,\n            in_len,\n            skip_0_check,\n            shift,\n        )\n    };\n    sponge\n}\n\n// The below is the loop to absorb elts into a poseidon sponge in chunks of 3\n// shift - the num of elts already absorbed to ensure the sponge's cache_size = 1\n// M - the max number of chunks required to absorb N things (must be comptime to compile)\n// NB: The 0 checks ('Found non-zero field...') are messy, but having a separate loop over N to check\n// for 0s costs 3N gates. Current approach is approx 2N gates.\n#[no_predicates]\nfn poseidon2_absorb_chunks_loop<let N: u32, let M: u32>(\n    in_sponge: Poseidon2Sponge,\n    input: [Field; N],\n    in_len: u32,\n    variable: bool,\n    shift: u32,\n) -> Poseidon2Sponge {\n    assert(in_len <= N, \"Given in_len to absorb is larger than the input array len\");\n    // When we have an existing sponge, we may have a shift of 0, and the final 'k+2' below = N\n    // The below avoids an overflow\n    let skip_last = 3 * M == N;\n    // Writing in_sponge: &mut does not compile\n    let mut sponge = in_sponge;\n    let mut should_add = true;\n    // The num of things left over after absorbing in 3s\n    let remainder = (in_len - shift) % 3;\n    // The num of chunks of 3 to absorb (maximum M)\n    let chunks = (in_len - shift - remainder) / 3;\n    for i in 0..M {\n        // Now we loop through cache size = 1 -> 3\n        should_add &= i != chunks;\n        // This is the index at the start of the chunk (for readability)\n        let k = 3 * i + shift;\n        if should_add {\n            // cache_size = 1, 2 => just assign\n            sponge.cache[1] = input[k];\n            sponge.cache[2] = input[k + 1];\n            // cache_size = 3 => duplex + perm\n            for j in 0..3 {\n                sponge.state[j] += sponge.cache[j];\n            }\n            sponge.state = std::hash::poseidon2_permutation(sponge.state, 4);\n            sponge.cache[0] = input[k + 2];\n            // cache_size is now 1 again, repeat loop\n        } else if (!variable) & (i != chunks) {\n            // if we are hashing a fixed len array which is a subarray, we check the remaining elts are 0\n            // NB: we don't check at i == chunks, because that chunk contains elts to be absorbed or checked below\n            let last_0 = if (i == M - 1) & (skip_last) {\n                0\n            } else {\n                input[k + 2]\n            };\n            let all_0 = (input[k] == 0) & (input[k + 1] == 0) & (last_0 == 0);\n            assert(all_0, \"Found non-zero field after breakpoint\");\n        }\n    }\n    // we have 'remainder' num of items left to absorb\n    should_add = true;\n    // below is to avoid overflows (i.e. if inlen is close to N)\n    let mut should_check = !variable;\n    for i in 0..3 {\n        should_add &= i != remainder;\n        should_check &= in_len - remainder + i != N;\n        if should_add {\n            // we want to absorb the final 'remainder' items\n            sponge.absorb(input[in_len - remainder + i]);\n        } else if should_check {\n            assert(input[in_len - remainder + i] == 0, \"Found non-zero field after breakpoint\");\n        }\n    }\n    sponge\n}\n\npub fn poseidon2_hash_with_separator_slice<T>(inputs: [Field], separator: T) -> Field\nwhere\n    T: ToField,\n{\n    let in_len = inputs.len() + 1;\n    let iv: Field = (in_len as Field) * TWO_POW_64;\n    let mut sponge = Poseidon2Sponge::new(iv);\n    sponge.absorb(separator.to_field());\n\n    for i in 0..inputs.len() {\n        sponge.absorb(inputs[i]);\n    }\n\n    sponge.squeeze()\n}\n\n#[no_predicates]\npub fn poseidon2_hash_bytes<let N: u32>(inputs: [u8; N]) -> Field {\n    let mut fields = [0; (N + 30) / 31];\n    let mut field_index = 0;\n    let mut current_field = [0; 31];\n    for i in 0..inputs.len() {\n        let index = i % 31;\n        current_field[index] = inputs[i];\n        if index == 30 {\n            fields[field_index] = field_from_bytes(current_field, false);\n            current_field = [0; 31];\n            field_index += 1;\n        }\n    }\n    if field_index != fields.len() {\n        fields[field_index] = field_from_bytes(current_field, false);\n    }\n    poseidon2_hash(fields)\n}\n\n#[test]\nfn poseidon_chunks_matches_fixed() {\n    let in_len = 501;\n    let mut input: [Field; 4096] = [0; 4096];\n    let mut fixed_input = [3; 501];\n    assert(in_len == fixed_input.len()); // sanity check\n    for i in 0..in_len {\n        input[i] = 3;\n    }\n    let sub_chunk_hash = poseidon2_hash_subarray(input, in_len);\n    let fixed_len_hash = poseidon::poseidon2::Poseidon2::hash(fixed_input, fixed_input.len());\n    assert(sub_chunk_hash == fixed_len_hash);\n}\n\n#[test]\nfn poseidon_chunks_matches_variable() {\n    let in_len = 501;\n    let mut input: [Field; 4096] = [0; 4096];\n    for i in 0..in_len {\n        input[i] = 3;\n    }\n    let variable_chunk_hash = poseidon2_cheaper_variable_hash(input, in_len);\n    let variable_len_hash = poseidon::poseidon2::Poseidon2::hash(input, in_len);\n    assert(variable_chunk_hash == variable_len_hash);\n}\n\n#[test]\nfn existing_sponge_poseidon_chunks_matches_fixed() {\n    let in_len = 501;\n    let mut input: [Field; 4096] = [0; 4096];\n    let mut fixed_input = [3; 501];\n    assert(in_len == fixed_input.len()); // sanity check\n    for i in 0..in_len {\n        input[i] = 3;\n    }\n    // absorb 250 of the 501 things\n    let empty_sponge = Poseidon2Sponge::new((in_len as Field) * TWO_POW_64);\n    let first_sponge = poseidon2_absorb_chunks_existing_sponge(empty_sponge, input, 250, true);\n    // now absorb the final 251 (since they are all 3s, im being lazy and not making a new array)\n    let mut final_sponge = poseidon2_absorb_chunks_existing_sponge(first_sponge, input, 251, true);\n    let fixed_len_hash = Poseidon2Sponge::hash(fixed_input, fixed_input.len());\n    assert(final_sponge.squeeze() == fixed_len_hash);\n}\n\n#[test]\nfn poseidon_chunks_empty_inputs() {\n    let in_len = 0;\n    let mut input: [Field; 4096] = [0; 4096];\n    let mut constructed_empty_sponge = poseidon2_absorb_chunks(input, in_len, true);\n    let mut first_sponge =\n        poseidon2_absorb_chunks_existing_sponge(constructed_empty_sponge, input, in_len, true);\n    assert(first_sponge.squeeze() == constructed_empty_sponge.squeeze());\n}\n\n#[test]\nfn smoke_sha256_to_field() {\n    let full_buffer = [\n        0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24,\n        25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47,\n        48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70,\n        71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93,\n        94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112,\n        113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130,\n        131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,\n        149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159,\n    ];\n    let result = sha256_to_field(full_buffer);\n\n    assert(result == 0x448ebbc9e1a31220a2f3830c18eef61b9bd070e5084b7fa2a359fe729184c7);\n\n    // to show correctness of the current ver (truncate one byte) vs old ver (mod full bytes):\n    let result_bytes = sha256::digest(full_buffer);\n    let truncated_field = crate::utils::field::field_from_bytes_32_trunc(result_bytes);\n    assert(truncated_field == result);\n    let mod_res = result + (result_bytes[31] as Field);\n    assert(mod_res == 0x448ebbc9e1a31220a2f3830c18eef61b9bd070e5084b7fa2a359fe729184e0);\n}\n\n#[test]\nfn compute_l2_l1_hash() {\n    // All zeroes\n    let hash_result =\n        compute_l2_to_l1_hash(AztecAddress::from_field(0), EthAddress::zero(), 0, 0, 0);\n    assert(hash_result == 0xb393978842a0fa3d3e1470196f098f473f9678e72463cb65ec4ab5581856c2);\n\n    // Non-zero case\n    let hash_result = compute_l2_to_l1_hash(\n        AztecAddress::from_field(1),\n        EthAddress::from_field(3),\n        5,\n        2,\n        4,\n    );\n    assert(hash_result == 0x3f88c1044a05e5340ed20466276500f6d45ca5603913b9091e957161734e16);\n}\n\n#[test]\nfn silo_l2_to_l1_message_matches_typescript() {\n    let version = 4;\n    let chainId = 5;\n\n    let hash = silo_l2_to_l1_message(\n        ScopedL2ToL1Message {\n            message: L2ToL1Message { recipient: EthAddress::from_field(1), content: 2, counter: 0 },\n            contract_address: AztecAddress::from_field(3),\n        },\n        version,\n        chainId,\n    );\n\n    // The following value was generated by `l2_to_l1_message.test.ts`\n    let hash_from_typescript = 0x00c6155d69febb9d5039b374dd4f77bf57b7c881709aa524a18acaa0bd57476a;\n\n    assert_eq(hash, hash_from_typescript);\n}\n"
    },
    "294": {
      "path": "/home/aztec-dev/aztec-packages/noir-projects/noir-protocol-circuits/crates/types/src/meta/mod.nr",
      "source": "use super::traits::{Deserialize, Packable, Serialize};\n\n/// Returns the typed expression of a trait method implementation.\n///\n/// This helper function is preferred over directly inlining with `$typ::target_method()` in a quote,\n/// as direct inlining would result in missing import warnings in the generated code (specifically,\n/// warnings that the trait implementation is not in scope).\n///\n/// # Note\n/// A copy of this function exists in `aztec-nr/aztec/src/macros/utils.nr`. We maintain separate copies\n/// because importing it there from here would cause the `target_trait` to be interpreted in the context\n/// of this crate, making it impossible to compile code for traits from that crate (e.g. NoteType).\ncomptime fn get_trait_impl_method(\n    typ: Type,\n    target_trait: Quoted,\n    target_method: Quoted,\n) -> TypedExpr {\n    let trait_constraint = target_trait.as_trait_constraint();\n    typ\n        .get_trait_impl(trait_constraint)\n        .expect(f\"Could not find impl for {target_trait} for type {typ}\")\n        .methods()\n        .filter(|m| m.name() == target_method)[0]\n        .as_typed_expr()\n}\n\n/// Generates code that deserializes a struct, primitive type, array or string from a field array.\n///\n/// # Parameters\n/// - `name`: The name of the current field being processed, used to identify fields for replacement.\n/// - `typ`: The type of the struct or field being deserialized (e.g., a custom struct, array, or primitive).\n/// - `field_array_name`: The name of the field array containing serialized field data (e.g., `\"values\"`).\n/// - `num_already_consumed`: The number of fields already processed in previous recursion calls.\n/// - `should_unpack`: A boolean indicating whether the type should be unpacked (see description of `Packable`\n/// and `Serialize` trait for more information about the difference between packing and serialization).\n///\n/// # Returns\n/// A tuple containing:\n/// - `Quoted`: A code that deserializes a given struct, primitive type, array, or string from the field array.\n/// - `u32`: The total number of fields consumed during deserialization (used for recursion).\n///\n/// # Nested Struct Example\n/// Given the following setup:\n/// ```\n/// struct UintNote {\n///     value: u128,\n///     owner: AztecAddress,\n///     randomness: Field,\n/// }\n///\n/// struct AztecAddress {\n///     inner: Field,\n/// }\n/// ```\n///\n/// If `UintNote` is the input type, the function will generate the following deserialization code:\n/// ```\n/// UintNote {\n///     value: fields[0] as u128,\n///     owner: AztecAddress {\n///         inner: fields[1],\n///     },\n///     randomness: fields[2],\n/// }\n/// ```\n/// # Nested Struct Example with Unpacking\n/// - given the same setup as above and given that u128, AztecAddress and Field implement the `Packable` trait\n///   the result we get is:\n/// ```\n/// UintNote {\n///     value: aztec::protocol_types::traits::Packable::unpack([fields[0]]),\n///     owner: aztec::protocol_types::traits::Packable::unpack([fields[1]]),\n///     randomness: aztec::protocol_types::traits::Packable::unpack([fields[2]]),\n/// }\n/// ```\n///\n/// # Panics\n/// - If the deserialization logic encounters a type it does not support.\n/// - If an incorrect number of fields are consumed when deserializing a string.\npub comptime fn generate_deserialize_from_fields(\n    name: Quoted,\n    typ: Type,\n    field_array_name: Quoted,\n    num_already_consumed: u32,\n    should_unpack: bool,\n) -> (Quoted, u32) {\n    let mut result = quote {};\n    // Counter for the number of fields consumed\n    let mut consumed_counter: u32 = 0;\n\n    // If the type implements `Packable`, its length will be assigned to the `maybe_packed_len_typ` variable.\n    let maybe_packed_len_typ = std::meta::typ::fresh_type_variable();\n    let packable_constraint = quote { Packable<$maybe_packed_len_typ> }.as_trait_constraint();\n\n    if (should_unpack & typ.implements(packable_constraint)) {\n        // Unpacking is enabled and the given type implements the `Packable` trait so we call the `unpack()`\n        // method, add the resulting field array to `aux_vars` and each field to `fields`.\n        let packed_len = maybe_packed_len_typ.as_constant().unwrap();\n\n        // We copy the packed fields into a new array and pass that to the unpack function in a quote\n        let mut packed_fields_quotes = &[];\n        for i in 0..packed_len {\n            let index_in_field_array = i + num_already_consumed;\n            packed_fields_quotes =\n                packed_fields_quotes.push_back(quote { $field_array_name[$index_in_field_array] });\n        }\n        let packed_fields = packed_fields_quotes.join(quote {,});\n\n        // Now we call unpack on the type\n        let unpack_method = get_trait_impl_method(typ, quote { Packable<_> }, quote { unpack });\n        result = quote { $unpack_method([ $packed_fields ]) };\n\n        consumed_counter = packed_len;\n    } else if typ.is_field() | typ.as_integer().is_some() | typ.is_bool() {\n        // The field is a primitive so we just reference it in the field array\n        result = quote { $field_array_name[$num_already_consumed] as $typ };\n        consumed_counter = 1;\n    } else if typ.as_data_type().is_some() {\n        // The field is a struct so we iterate over each struct field and recursively call\n        // `generate_deserialize_from_fields`\n        let (nested_def, generics) = typ.as_data_type().unwrap();\n        let nested_name = nested_def.name();\n        let mut deserialized_fields_list = &[];\n\n        // Iterate over each field in the struct\n        for field in nested_def.fields(generics) {\n            let (field_name, field_type) = field;\n            // Recursively call `generate_deserialize_from_fields` for each field in the struct\n            let (deserialized_field, num_consumed_in_recursion) = generate_deserialize_from_fields(\n                field_name,\n                field_type,\n                field_array_name,\n                consumed_counter + num_already_consumed,\n                should_unpack,\n            );\n            // We increment the consumed counter by the number of fields consumed in the recursion\n            consumed_counter += num_consumed_in_recursion;\n            // We add the deserialized field to the list of deserialized fields.\n            // E.g. `value: u128 { lo: fields[0], hi: fields[1] }`\n            deserialized_fields_list =\n                deserialized_fields_list.push_back(quote { $field_name: $deserialized_field });\n        }\n\n        // We can construct the struct from the deserialized fields\n        let deserialized_fields = deserialized_fields_list.join(quote {,});\n        result = quote {\n                $nested_name {\n                    $deserialized_fields\n                }\n            };\n    } else if typ.as_array().is_some() {\n        // The field is an array so we iterate over each element and recursively call\n        // `generate_deserialize_from_fields`\n        let (element_type, array_len) = typ.as_array().unwrap();\n        let array_len = array_len.as_constant().unwrap();\n        let mut array_fields_list = &[];\n\n        // Iterate over each element in the array\n        for _ in 0..array_len {\n            // Recursively call `generate_deserialize_from_fields` for each element in the array\n            let (deserialized_field, num_consumed_in_recursion) = generate_deserialize_from_fields(\n                name,\n                element_type,\n                field_array_name,\n                consumed_counter + num_already_consumed,\n                should_unpack,\n            );\n            // We increment the consumed counter by the number of fields consumed in the recursion\n            consumed_counter += num_consumed_in_recursion;\n            // We add the deserialized field to the list of deserialized fields.\n            array_fields_list = array_fields_list.push_back(deserialized_field);\n        }\n\n        // We can construct the array from the deserialized fields\n        let array_fields = array_fields_list.join(quote {,});\n        result = quote { [ $array_fields ] };\n    } else if typ.as_str().is_some() {\n        // The field is a string and we expect each byte of the string to be represented as 1 field in the field\n        // array. So we iterate over the string length and deserialize each character as u8 in the recursive call\n        // to `generate_deserialize_from_fields`.\n        let length_type = typ.as_str().unwrap();\n        let str_len = length_type.as_constant().unwrap();\n        let mut byte_list = &[];\n\n        // Iterate over each character in the string\n        for _ in 0..str_len {\n            // Recursively call `generate_deserialize_from_fields` for each character in the string\n            let (deserialized_field, num_consumed_in_recursion) = generate_deserialize_from_fields(\n                name,\n                quote {u8}.as_type(),\n                field_array_name,\n                consumed_counter + num_already_consumed,\n                should_unpack,\n            );\n\n            // We should consume just one field in the recursion so we sanity check that\n            assert_eq(\n                num_consumed_in_recursion,\n                1,\n                \"Incorrect number of fields consumed in string deserialization\",\n            );\n\n            // We increment the consumed counter by 1 as we have consumed one field\n            consumed_counter += 1;\n\n            // We add the deserialized field to the list of deserialized fields.\n            // E.g. `fields[6] as u8`\n            byte_list = byte_list.push_back(deserialized_field);\n        }\n\n        // We construct the string from the deserialized fields\n        let bytes = byte_list.join(quote {,});\n        result = quote { [ $bytes ].as_str_unchecked() };\n    } else {\n        panic(\n            f\"Unsupported type for serialization of argument {name} and type {typ}\",\n        )\n    }\n\n    (result, consumed_counter)\n}\n\n/// Generates code that serializes a type into an array of fields. Also generates auxiliary variables if necessary\n/// for serialization. If `should_pack` is true, we check if the type implements the `Packable` trait and pack it\n/// if it does.\n///\n/// # Parameters\n/// - `name`: The base identifier (e.g., `self`, `some_var`).\n/// - `typ`: The type being serialized (e.g., a custom struct, array, or primitive type).\n/// - `should_pack`: A boolean indicating whether the type should be packed.\n///\n/// # Returns\n/// A tuple containing:\n/// - A flattened array of `Quoted` field references representing the serialized fields.\n/// - An array of `Quoted` auxiliary variables needed for serialization, such as byte arrays for strings.\n///\n/// # Examples\n///\n/// ## Struct\n/// Given the following struct:\n/// ```rust\n/// struct MockStruct {\n///     a: Field,\n///     b: Field,\n/// }\n/// ```\n///\n/// Serializing the struct:\n/// ```rust\n/// generate_serialize_to_fields(quote { my_mock_struct }, MockStruct, false)\n/// // Returns:\n/// // ([`my_mock_struct.a`, `my_mock_struct.b`], [])\n/// ```\n///\n/// ## Nested Struct\n/// For a more complex struct:\n/// ```rust\n/// struct NestedStruct {\n///     m1: MockStruct,\n///     m2: MockStruct,\n/// }\n/// ```\n///\n/// Serialization output:\n/// ```rust\n/// generate_serialize_to_fields(quote { self }, NestedStruct, false)\n/// // Returns:\n/// // ([`self.m1.a`, `self.m1.b`, `self.m2.a`, `self.m2.b`], [])\n/// ```\n///\n/// ## Array\n/// For an array type:\n/// ```rust\n/// generate_serialize_to_fields(quote { my_array }, [Field; 3], false)\n/// // Returns:\n/// // ([`my_array[0]`, `my_array[1]`, `my_array[2]`], [])\n/// ```\n///\n/// ## String\n/// For a string field, where each character is serialized as a `Field`:\n/// ```rust\n/// generate_serialize_to_fields(quote { my_string }, StringType, false)\n/// // Returns:\n/// // ([`my_string_as_bytes[0] as Field`, `my_string_as_bytes[1] as Field`, ...],\n/// // [`let my_string_as_bytes = my_string.as_bytes()`])\n/// ```\n///\n/// ## Nested Struct with packing enabled\n/// - u128 has a `Packable` implementation hence it will be packed.\n///\n/// For a more complex struct:\n/// ```rust\n/// struct MyStruct {\n///     value: u128,\n///     value2: Field,\n/// }\n/// ```\n///\n/// # Panics\n/// - If the type is unsupported for serialization.\n/// - If the provided `typ` contains invalid constants or incompatible structures.\npub comptime fn generate_serialize_to_fields(\n    name: Quoted,\n    typ: Type,\n    should_pack: bool,\n) -> ([Quoted], [Quoted]) {\n    let mut fields = &[];\n    let mut aux_vars = &[];\n\n    // If the type implements `Packable`, its length will be assigned to the `maybe_packed_len_typ` variable.\n    let maybe_packed_len_typ = std::meta::typ::fresh_type_variable();\n    let packable_constraint =\n        quote { crate::traits::Packable<$maybe_packed_len_typ> }.as_trait_constraint();\n\n    if (should_pack & typ.implements(packable_constraint)) {\n        // Packing is enabled and the given type implements the `Packable` trait so we call the `pack()`\n        // method, add the resulting field array to `aux_vars` and each field to `fields`.\n        let packed_len = maybe_packed_len_typ.as_constant().unwrap();\n\n        // We collapse the name to a one that gets tokenized as a single token (e.g. \"self.value\" -> \"self_value\").\n        let name_at_one_token = collapse_to_one_token(name);\n        let packed_struct_name = f\"{name_at_one_token}_aux_var\".quoted_contents();\n\n        // We add the individual fields to the fields array\n        let pack_method = get_trait_impl_method(\n            typ,\n            quote { crate::traits::Packable<$packed_len> },\n            quote { pack },\n        );\n        let packed_struct = quote { let $packed_struct_name = $pack_method($name) };\n        for i in 0..packed_len {\n            fields = fields.push_back(quote { $packed_struct_name[$i] });\n        }\n\n        // We add the new auxiliary variable to the aux_vars array\n        aux_vars = aux_vars.push_back(packed_struct);\n    } else if typ.is_field() {\n        // For field we just add the value to fields\n        fields = fields.push_back(name);\n    } else if typ.as_integer().is_some() | typ.is_bool() {\n        // For integer and bool we just cast to Field and add the value to fields\n        fields = fields.push_back(quote { $name as Field });\n    } else if typ.as_data_type().is_some() {\n        // For struct we pref\n        let nested_struct = typ.as_data_type().unwrap();\n        let params = nested_struct.0.fields(nested_struct.1);\n        let struct_flattened = params.map(|(param_name, param_type): (Quoted, Type)| {\n            let maybe_prefixed_name = if name == quote {} {\n                // Triggered when the param name is of a value available in the current scope (e.g. a function\n                // argument) --> then we don't prefix the name with anything.\n                param_name\n            } else {\n                // Triggered when we want to prefix the param name with the `name` from function input. This\n                // can typically be `self` when implementing a method on a struct.\n                quote { $name.$param_name }\n            };\n            generate_serialize_to_fields(quote {$maybe_prefixed_name}, param_type, should_pack)\n        });\n        let struct_flattened_fields = struct_flattened.fold(\n            &[],\n            |acc: [Quoted], (fields, _): (_, [Quoted])| acc.append(fields),\n        );\n        let struct_flattened_aux_vars = struct_flattened.fold(\n            &[],\n            |acc: [Quoted], (_, aux_vars): ([Quoted], _)| acc.append(aux_vars),\n        );\n        fields = fields.append(struct_flattened_fields);\n        aux_vars = aux_vars.append(struct_flattened_aux_vars);\n    } else if typ.as_array().is_some() {\n        // For array we recursively call `generate_serialize_to_fields(...)` for each element\n        let (element_type, array_len) = typ.as_array().unwrap();\n        let array_len = array_len.as_constant().unwrap();\n        for i in 0..array_len {\n            let (element_fields, element_aux_vars) =\n                generate_serialize_to_fields(quote { $name[$i] }, element_type, should_pack);\n            fields = fields.append(element_fields);\n            aux_vars = aux_vars.append(element_aux_vars);\n        }\n    } else if typ.as_str().is_some() {\n        // For string we convert the value to bytes, we store the `as_bytes` in an auxiliary variables and\n        // then we add each byte to fields as a Field\n        let length_type = typ.as_str().unwrap();\n        let str_len = length_type.as_constant().unwrap();\n        let as_member = name.as_expr().unwrap().as_member_access();\n        let var_name = if as_member.is_some() {\n            as_member.unwrap().1\n        } else {\n            name\n        };\n        let as_bytes_name = f\"{var_name}_as_bytes\".quoted_contents();\n        let as_bytes = quote { let $as_bytes_name = $name.as_bytes() };\n        for i in 0..str_len {\n            fields = fields.push_back(quote { $as_bytes_name[$i] as Field });\n        }\n        aux_vars = aux_vars.push_back(as_bytes);\n    } else {\n        panic(\n            f\"Unsupported type for serialization of argument {name} and type {typ}\",\n        )\n    }\n\n    (fields, aux_vars)\n}\n\n/// From a quote that gets tokenized to a multiple tokens we collapse it to a single token by replacing all `.` with `_`.\n/// E.g. \"self.values[0]\" -> \"self_values_0_\"\ncomptime fn collapse_to_one_token(q: Quoted) -> Quoted {\n    let tokens = q.tokens();\n\n    let mut single_token = quote {};\n    for token in tokens {\n        let new_token = if ((token == quote {.}) | (token == quote {[}) | (token == quote {]})) {\n            quote {_}\n        } else {\n            token\n        };\n        single_token = f\"{single_token}{new_token}\".quoted_contents();\n    }\n    single_token\n}\n\npub(crate) comptime fn derive_serialize(s: TypeDefinition) -> Quoted {\n    let typ = s.as_type();\n    let (fields, aux_vars) = generate_serialize_to_fields(quote { self }, typ, false);\n    let aux_vars_for_serialization = if aux_vars.len() > 0 {\n        let joint = aux_vars.join(quote {;});\n        quote { $joint; }\n    } else {\n        quote {}\n    };\n\n    let field_serializations = fields.join(quote {,});\n    let serialized_len = fields.len();\n    quote {\n        impl Serialize<$serialized_len> for $typ {\n            fn serialize(self) -> [Field; $serialized_len] {\n                $aux_vars_for_serialization\n                [ $field_serializations ]\n            }\n        }\n    }\n}\n\npub(crate) comptime fn derive_deserialize(s: TypeDefinition) -> Quoted {\n    let typ = s.as_type();\n    let (fields, _) = generate_serialize_to_fields(quote { self }, typ, false);\n    let serialized_len = fields.len();\n    let (deserialized, _) =\n        generate_deserialize_from_fields(quote { self }, typ, quote { serialized }, 0, false);\n    quote {\n        impl Deserialize<$serialized_len> for $typ {\n            fn deserialize(serialized: [Field; $serialized_len]) -> Self {\n                $deserialized\n            }\n        }\n    }\n}\n\n/// Generates `Packable` implementation for a given struct and returns the packed length.\n///\n/// Note: We are having this function separate from `derive_packable` because we use this in the note macros to get\n/// the packed length of a note as well as the `Packable` implementation. We need the length to be able to register\n/// the note in the global `NOTES` map. There the length is used to generate partial note helper functions.\npub comptime fn derive_packable_and_get_packed_len(s: TypeDefinition) -> (Quoted, u32) {\n    let packing_enabled = true;\n\n    let typ = s.as_type();\n    let (fields, aux_vars) = generate_serialize_to_fields(quote { self }, typ, packing_enabled);\n    let aux_vars_for_packing = if aux_vars.len() > 0 {\n        let joint = aux_vars.join(quote {;});\n        quote { $joint; }\n    } else {\n        quote {}\n    };\n\n    let (unpacked, _) =\n        generate_deserialize_from_fields(quote { self }, typ, quote { packed }, 0, packing_enabled);\n\n    let field_packings = fields.join(quote {,});\n    let packed_len = fields.len();\n    let packable_trait: TraitConstraint = quote { Packable<$packed_len> }.as_trait_constraint();\n    (\n        quote {\n        impl $packable_trait for $typ {\n            fn pack(self) -> [Field; $packed_len] {\n                $aux_vars_for_packing\n                [ $field_packings ]\n            }\n\n            fn unpack(packed: [Field; $packed_len]) -> Self {\n                $unpacked\n            }\n        }\n    },\n        packed_len,\n    )\n}\n\npub(crate) comptime fn derive_packable(s: TypeDefinition) -> Quoted {\n    let (packable_impl, _) = derive_packable_and_get_packed_len(s);\n    packable_impl\n}\n\n#[derive(Packable, Serialize, Deserialize, Eq)]\npub struct Smol {\n    a: Field,\n    b: Field,\n}\n\n#[derive(Serialize, Deserialize, Eq)]\npub struct HasArray {\n    a: [Field; 2],\n    b: bool,\n}\n\n#[derive(Serialize, Deserialize, Eq)]\npub struct Fancier {\n    a: Smol,\n    b: [Field; 2],\n    c: [u8; 3],\n    d: str<16>,\n}\n\nfn main() {\n    assert(false);\n}\n\n#[test]\nfn smol_test() {\n    let smol = Smol { a: 1, b: 2 };\n    let serialized = smol.serialize();\n    assert(serialized == [1, 2], serialized);\n    let deserialized = Smol::deserialize(serialized);\n    assert(deserialized == smol);\n\n    // None of the struct members implements the `Packable` trait so the packed and serialized data should be the same\n    let packed = smol.pack();\n    assert_eq(packed, serialized, \"Packed does not match serialized\");\n}\n\n#[test]\nfn has_array_test() {\n    let has_array = HasArray { a: [1, 2], b: true };\n    let serialized = has_array.serialize();\n    assert(serialized == [1, 2, 1], serialized);\n    let deserialized = HasArray::deserialize(serialized);\n    assert(deserialized == has_array);\n}\n\n#[test]\nfn fancier_test() {\n    let fancier =\n        Fancier { a: Smol { a: 1, b: 2 }, b: [0, 1], c: [1, 2, 3], d: \"metaprogramming!\" };\n    let serialized = fancier.serialize();\n    assert(\n        serialized\n            == [\n                1, 2, 0, 1, 1, 2, 3, 0x6d, 0x65, 0x74, 0x61, 0x70, 0x72, 0x6f, 0x67, 0x72, 0x61,\n                0x6d, 0x6d, 0x69, 0x6e, 0x67, 0x21,\n            ],\n        serialized,\n    );\n    let deserialized = Fancier::deserialize(serialized);\n    assert(deserialized == fancier);\n}\n"
    },
    "317": {
      "path": "/home/aztec-dev/aztec-packages/noir-projects/noir-protocol-circuits/crates/types/src/storage/map.nr",
      "source": "use crate::{hash::poseidon2_hash, traits::ToField};\n\npub fn derive_storage_slot_in_map<K>(storage_slot: Field, key: K) -> Field\nwhere\n    K: ToField,\n{\n    poseidon2_hash([storage_slot, key.to_field()])\n}\n\nmod test {\n    use crate::{address::AztecAddress, storage::map::derive_storage_slot_in_map, traits::FromField};\n\n    #[test]\n    fn test_derive_storage_slot_in_map_matches_typescript() {\n        let map_slot = 0x132258fb6962c4387ba659d9556521102d227549a386d39f0b22d1890d59c2b5;\n        let key = AztecAddress::from_field(\n            0x302dbc2f9b50a73283d5fb2f35bc01eae8935615817a0b4219a057b2ba8a5a3f,\n        );\n\n        let slot = derive_storage_slot_in_map(map_slot, key);\n\n        // The following value was generated by `map_slot.test.ts`\n        let slot_from_typescript =\n            0x15b9fe39449affd8b377461263e9d2b610b9ad40580553500b4e41d9cbd887ac;\n\n        assert_eq(slot, slot_from_typescript);\n    }\n}\n"
    },
    "335": {
      "path": "/home/aztec-dev/aztec-packages/noir-projects/noir-protocol-circuits/crates/types/src/type_packing.nr",
      "source": "use crate::traits::Packable;\n\nglobal BOOL_PACKED_LEN: u32 = 1;\nglobal U8_PACKED_LEN: u32 = 1;\nglobal U16_PACKED_LEN: u32 = 1;\nglobal U32_PACKED_LEN: u32 = 1;\nglobal U64_PACKED_LEN: u32 = 1;\nglobal U128_PACKED_LEN: u32 = 1;\nglobal FIELD_PACKED_LEN: u32 = 1;\nglobal I8_PACKED_LEN: u32 = 1;\nglobal I16_PACKED_LEN: u32 = 1;\nglobal I32_PACKED_LEN: u32 = 1;\nglobal I64_PACKED_LEN: u32 = 1;\n\nimpl Packable<BOOL_PACKED_LEN> for bool {\n    fn pack(self) -> [Field; BOOL_PACKED_LEN] {\n        [self as Field]\n    }\n\n    fn unpack(fields: [Field; BOOL_PACKED_LEN]) -> bool {\n        fields[0] as bool\n    }\n}\n\nimpl Packable<U8_PACKED_LEN> for u8 {\n    fn pack(self) -> [Field; U8_PACKED_LEN] {\n        [self as Field]\n    }\n\n    fn unpack(fields: [Field; U8_PACKED_LEN]) -> Self {\n        fields[0] as u8\n    }\n}\n\nimpl Packable<U16_PACKED_LEN> for u16 {\n    fn pack(self) -> [Field; U16_PACKED_LEN] {\n        [self as Field]\n    }\n\n    fn unpack(fields: [Field; U16_PACKED_LEN]) -> Self {\n        fields[0] as u16\n    }\n}\n\nimpl Packable<U32_PACKED_LEN> for u32 {\n    fn pack(self) -> [Field; U32_PACKED_LEN] {\n        [self as Field]\n    }\n\n    fn unpack(fields: [Field; U32_PACKED_LEN]) -> Self {\n        fields[0] as u32\n    }\n}\n\nimpl Packable<U64_PACKED_LEN> for u64 {\n    fn pack(self) -> [Field; U64_PACKED_LEN] {\n        [self as Field]\n    }\n\n    fn unpack(fields: [Field; U64_PACKED_LEN]) -> Self {\n        fields[0] as u64\n    }\n}\n\nimpl Packable<U128_PACKED_LEN> for u128 {\n    fn pack(self) -> [Field; U128_PACKED_LEN] {\n        [self as Field]\n    }\n\n    fn unpack(fields: [Field; U128_PACKED_LEN]) -> Self {\n        fields[0] as u128\n    }\n}\n\nimpl Packable<FIELD_PACKED_LEN> for Field {\n    fn pack(self) -> [Field; FIELD_PACKED_LEN] {\n        [self]\n    }\n\n    fn unpack(fields: [Field; FIELD_PACKED_LEN]) -> Self {\n        fields[0]\n    }\n}\n\nimpl Packable<I8_PACKED_LEN> for i8 {\n    fn pack(self) -> [Field; I8_PACKED_LEN] {\n        [self as Field]\n    }\n\n    fn unpack(fields: [Field; I8_PACKED_LEN]) -> Self {\n        fields[0] as i8\n    }\n}\n\nimpl Packable<I16_PACKED_LEN> for i16 {\n    fn pack(self) -> [Field; I16_PACKED_LEN] {\n        [self as Field]\n    }\n\n    fn unpack(fields: [Field; I16_PACKED_LEN]) -> Self {\n        fields[0] as i16\n    }\n}\n\nimpl Packable<I32_PACKED_LEN> for i32 {\n    fn pack(self) -> [Field; I32_PACKED_LEN] {\n        [self as Field]\n    }\n\n    fn unpack(fields: [Field; I32_PACKED_LEN]) -> Self {\n        fields[0] as i32\n    }\n}\n\nimpl Packable<I64_PACKED_LEN> for i64 {\n    fn pack(self) -> [Field; I64_PACKED_LEN] {\n        [self as Field]\n    }\n\n    fn unpack(fields: [Field; I64_PACKED_LEN]) -> Self {\n        fields[0] as i64\n    }\n}\n\nimpl<T, let N: u32, let M: u32> Packable<N * M> for [T; N]\nwhere\n    T: Packable<M>,\n{\n    fn pack(self) -> [Field; N * M] {\n        let mut result: [Field; N * M] = std::mem::zeroed();\n        let mut serialized: [Field; M] = std::mem::zeroed();\n        for i in 0..N {\n            serialized = self[i].pack();\n            for j in 0..M {\n                result[i * M + j] = serialized[j];\n            }\n        }\n        result\n    }\n\n    fn unpack(fields: [Field; N * M]) -> Self {\n        let mut reader = crate::utils::reader::Reader::new(fields);\n        let mut result: [T; N] = std::mem::zeroed();\n        reader.read_struct_array::<T, M, N>(Packable::unpack, result)\n    }\n}\n\n#[test]\nfn test_u16_packing() {\n    let a: u16 = 10;\n    assert_eq(a, u16::unpack(a.pack()));\n}\n\n#[test]\nfn test_i8_packing() {\n    let a: i8 = -10;\n    assert_eq(a, i8::unpack(a.pack()));\n}\n\n#[test]\nfn test_i16_packing() {\n    let a: i16 = -10;\n    assert_eq(a, i16::unpack(a.pack()));\n}\n\n#[test]\nfn test_i32_packing() {\n    let a: i32 = -10;\n    assert_eq(a, i32::unpack(a.pack()));\n}\n\n#[test]\nfn test_i64_packing() {\n    let a: i64 = -10;\n    assert_eq(a, i64::unpack(a.pack()));\n}\n"
    },
    "336": {
      "path": "/home/aztec-dev/aztec-packages/noir-projects/noir-protocol-circuits/crates/types/src/type_serialization.nr",
      "source": "use crate::traits::{Deserialize, Serialize};\n\nglobal BOOL_SERIALIZED_LEN: u32 = 1;\nglobal U8_SERIALIZED_LEN: u32 = 1;\nglobal U16_SERIALIZED_LEN: u32 = 1;\nglobal U32_SERIALIZED_LEN: u32 = 1;\nglobal U64_SERIALIZED_LEN: u32 = 1;\nglobal U128_SERIALIZED_LEN: u32 = 1;\nglobal FIELD_SERIALIZED_LEN: u32 = 1;\nglobal I8_SERIALIZED_LEN: u32 = 1;\nglobal I16_SERIALIZED_LEN: u32 = 1;\nglobal I32_SERIALIZED_LEN: u32 = 1;\nglobal I64_SERIALIZED_LEN: u32 = 1;\n\nimpl Serialize<BOOL_SERIALIZED_LEN> for bool {\n    fn serialize(self) -> [Field; BOOL_SERIALIZED_LEN] {\n        [self as Field]\n    }\n}\n\nimpl Deserialize<BOOL_SERIALIZED_LEN> for bool {\n    fn deserialize(fields: [Field; BOOL_SERIALIZED_LEN]) -> bool {\n        fields[0] as bool\n    }\n}\n\nimpl Serialize<U8_SERIALIZED_LEN> for u8 {\n    fn serialize(self) -> [Field; U8_SERIALIZED_LEN] {\n        [self as Field]\n    }\n}\n\nimpl Deserialize<U8_SERIALIZED_LEN> for u8 {\n    fn deserialize(fields: [Field; U8_SERIALIZED_LEN]) -> Self {\n        fields[0] as u8\n    }\n}\n\nimpl Serialize<U16_SERIALIZED_LEN> for u16 {\n    fn serialize(self) -> [Field; U16_SERIALIZED_LEN] {\n        [self as Field]\n    }\n}\n\nimpl Deserialize<U16_SERIALIZED_LEN> for u16 {\n    fn deserialize(fields: [Field; U16_SERIALIZED_LEN]) -> Self {\n        fields[0] as u16\n    }\n}\n\nimpl Serialize<U32_SERIALIZED_LEN> for u32 {\n    fn serialize(self) -> [Field; U32_SERIALIZED_LEN] {\n        [self as Field]\n    }\n}\n\nimpl Deserialize<U32_SERIALIZED_LEN> for u32 {\n    fn deserialize(fields: [Field; U32_SERIALIZED_LEN]) -> Self {\n        fields[0] as u32\n    }\n}\n\nimpl Serialize<U64_SERIALIZED_LEN> for u64 {\n    fn serialize(self) -> [Field; U64_SERIALIZED_LEN] {\n        [self as Field]\n    }\n}\n\nimpl Deserialize<U64_SERIALIZED_LEN> for u64 {\n    fn deserialize(fields: [Field; U64_SERIALIZED_LEN]) -> Self {\n        fields[0] as u64\n    }\n}\n\nimpl Serialize<U128_SERIALIZED_LEN> for u128 {\n    fn serialize(self) -> [Field; U128_SERIALIZED_LEN] {\n        [self as Field]\n    }\n}\n\nimpl Deserialize<U128_SERIALIZED_LEN> for u128 {\n    fn deserialize(fields: [Field; U128_SERIALIZED_LEN]) -> Self {\n        fields[0] as u128\n    }\n}\n\nimpl Serialize<FIELD_SERIALIZED_LEN> for Field {\n    fn serialize(self) -> [Field; FIELD_SERIALIZED_LEN] {\n        [self]\n    }\n}\n\nimpl Deserialize<FIELD_SERIALIZED_LEN> for Field {\n    fn deserialize(fields: [Field; FIELD_SERIALIZED_LEN]) -> Self {\n        fields[0]\n    }\n}\n\nimpl Serialize<I8_SERIALIZED_LEN> for i8 {\n    fn serialize(self) -> [Field; I8_SERIALIZED_LEN] {\n        [self as Field]\n    }\n}\n\nimpl Deserialize<I8_SERIALIZED_LEN> for i8 {\n    fn deserialize(fields: [Field; I8_SERIALIZED_LEN]) -> Self {\n        fields[0] as i8\n    }\n}\n\nimpl Serialize<I16_SERIALIZED_LEN> for i16 {\n    fn serialize(self) -> [Field; I16_SERIALIZED_LEN] {\n        [self as Field]\n    }\n}\n\nimpl Deserialize<I16_SERIALIZED_LEN> for i16 {\n    fn deserialize(fields: [Field; I16_SERIALIZED_LEN]) -> Self {\n        fields[0] as i16\n    }\n}\n\nimpl Serialize<I32_SERIALIZED_LEN> for i32 {\n    fn serialize(self) -> [Field; I32_SERIALIZED_LEN] {\n        [self as Field]\n    }\n}\n\nimpl Deserialize<I32_SERIALIZED_LEN> for i32 {\n    fn deserialize(fields: [Field; I32_SERIALIZED_LEN]) -> Self {\n        fields[0] as i32\n    }\n}\n\nimpl Serialize<I64_SERIALIZED_LEN> for i64 {\n    fn serialize(self) -> [Field; I64_SERIALIZED_LEN] {\n        [self as Field]\n    }\n}\n\nimpl Deserialize<I64_SERIALIZED_LEN> for i64 {\n    fn deserialize(fields: [Field; I64_SERIALIZED_LEN]) -> Self {\n        fields[0] as i64\n    }\n}\n\nimpl<T, let N: u32, let M: u32> Serialize<N * M> for [T; N]\nwhere\n    T: Serialize<M>,\n{\n    fn serialize(self) -> [Field; N * M] {\n        let mut result: [Field; N * M] = std::mem::zeroed();\n        let mut serialized: [Field; M] = std::mem::zeroed();\n        for i in 0..N {\n            serialized = self[i].serialize();\n            for j in 0..M {\n                result[i * M + j] = serialized[j];\n            }\n        }\n        result\n    }\n}\n\nimpl<T, let N: u32, let M: u32> Deserialize<N * M> for [T; N]\nwhere\n    T: Deserialize<M>,\n{\n    fn deserialize(fields: [Field; N * M]) -> Self {\n        let mut reader = crate::utils::reader::Reader::new(fields);\n        let mut result: [T; N] = std::mem::zeroed();\n        reader.read_struct_array::<T, M, N>(Deserialize::deserialize, result)\n    }\n}\n\n#[test]\nfn test_u16_serialization() {\n    let a: u16 = 10;\n    assert_eq(a, u16::deserialize(a.serialize()));\n}\n\n#[test]\nfn test_i8_serialization() {\n    let a: i8 = -10;\n    assert_eq(a, i8::deserialize(a.serialize()));\n}\n\n#[test]\nfn test_i16_serialization() {\n    let a: i16 = -10;\n    assert_eq(a, i16::deserialize(a.serialize()));\n}\n\n#[test]\nfn test_i32_serialization() {\n    let a: i32 = -10;\n    assert_eq(a, i32::deserialize(a.serialize()));\n}\n\n#[test]\nfn test_i64_serialization() {\n    let a: i64 = -10;\n    assert_eq(a, i64::deserialize(a.serialize()));\n}\n"
    },
    "355": {
      "path": "/home/aztec-dev/aztec-packages/noir-projects/noir-protocol-circuits/crates/types/src/utils/reader.nr",
      "source": "pub struct Reader<let N: u32> {\n    data: [Field; N],\n    offset: u32,\n}\n\nimpl<let N: u32> Reader<N> {\n    pub fn new(data: [Field; N]) -> Self {\n        Self { data, offset: 0 }\n    }\n\n    pub fn read(&mut self) -> Field {\n        let result = self.data[self.offset];\n        self.offset += 1;\n        result\n    }\n\n    pub fn read_u32(&mut self) -> u32 {\n        self.read() as u32\n    }\n\n    pub fn read_bool(&mut self) -> bool {\n        self.read() as bool\n    }\n\n    pub fn read_array<let K: u32>(&mut self) -> [Field; K] {\n        let mut result = [0; K];\n        for i in 0..K {\n            result[i] = self.data[self.offset + i];\n        }\n        self.offset += K;\n        result\n    }\n\n    pub fn read_struct<T, let K: u32>(&mut self, deserialise: fn([Field; K]) -> T) -> T {\n        let result = deserialise(self.read_array());\n        result\n    }\n\n    pub fn read_struct_array<T, let K: u32, let C: u32>(\n        &mut self,\n        deserialise: fn([Field; K]) -> T,\n        mut result: [T; C],\n    ) -> [T; C] {\n        for i in 0..C {\n            result[i] = self.read_struct(deserialise);\n        }\n        result\n    }\n\n    pub fn finish(self) {\n        assert(self.offset == self.data.len(), \"Reader did not read all data\");\n    }\n}\n"
    },
    "43": {
      "path": "std/panic.nr",
      "source": "pub fn panic<T, U, let N: u32>(message: fmtstr<N, T>) -> U {\n    assert(false, message);\n    crate::mem::zeroed()\n}\n"
    },
    "51": {
      "path": "/home/aztec-dev/aztec-packages/noir-projects/noir-contracts/contracts/app/price_feed_contract/src/main.nr",
      "source": "mod asset;\n\nuse dep::aztec::macros::aztec;\n\n#[aztec]\npub contract PriceFeed {\n    use crate::asset::Asset;\n    use dep::aztec::prelude::{Map, PublicMutable};\n\n    use dep::aztec::macros::{functions::{public, view}, storage::storage};\n\n    // Storage structure, containing all storage, and specifying what slots they use.\n    #[storage]\n    struct Storage<Context> {\n        assets: Map<Field, PublicMutable<Asset, Context>, Context>,\n    }\n\n    #[public]\n    fn set_price(asset_id: Field, price: u128) {\n        let asset = storage.assets.at(asset_id);\n        asset.write(Asset { price });\n    }\n\n    #[public]\n    #[view]\n    fn get_price(asset_id: Field) -> Asset {\n        storage.assets.at(asset_id).read()\n    }\n}\n"
    },
    "61": {
      "path": "/home/aztec-dev/aztec-packages/noir-projects/aztec-nr/aztec/src/context/public_context.nr",
      "source": "use crate::context::gas::GasOpts;\nuse crate::hash::{\n    compute_l1_to_l2_message_hash, compute_l1_to_l2_message_nullifier, compute_secret_hash,\n};\nuse dep::protocol_types::abis::function_selector::FunctionSelector;\nuse dep::protocol_types::address::{AztecAddress, EthAddress};\nuse dep::protocol_types::constants::MAX_FIELD_VALUE;\nuse dep::protocol_types::traits::{Empty, FromField, Packable, Serialize, ToField};\n\npub struct PublicContext {\n    pub args_hash: Option<Field>,\n    pub compute_args_hash: fn() -> Field,\n}\n\nimpl PublicContext {\n    pub fn new(compute_args_hash: fn() -> Field) -> Self {\n        PublicContext { args_hash: Option::none(), compute_args_hash }\n    }\n\n    pub fn emit_public_log<T, let N: u32>(_self: &mut Self, log: T)\n    where\n        T: Serialize<N>,\n    {\n        // Safety: AVM opcodes are constrained by the AVM itself\n        unsafe { emit_public_log(Serialize::serialize(log).as_slice()) };\n    }\n\n    pub fn note_hash_exists(_self: Self, note_hash: Field, leaf_index: Field) -> bool {\n        // Safety: AVM opcodes are constrained by the AVM itself\n        unsafe { note_hash_exists(note_hash, leaf_index) } == 1\n    }\n\n    pub fn l1_to_l2_msg_exists(_self: Self, msg_hash: Field, msg_leaf_index: Field) -> bool {\n        // Safety: AVM opcodes are constrained by the AVM itself\n        unsafe { l1_to_l2_msg_exists(msg_hash, msg_leaf_index) } == 1\n    }\n\n    pub fn nullifier_exists(_self: Self, unsiloed_nullifier: Field, address: AztecAddress) -> bool {\n        // Safety: AVM opcodes are constrained by the AVM itself\n        unsafe { nullifier_exists(unsiloed_nullifier, address.to_field()) } == 1\n    }\n\n    pub fn consume_l1_to_l2_message(\n        &mut self,\n        content: Field,\n        secret: Field,\n        sender: EthAddress,\n        leaf_index: Field,\n    ) {\n        let secret_hash = compute_secret_hash(secret);\n        let message_hash = compute_l1_to_l2_message_hash(\n            sender,\n            self.chain_id(),\n            /*recipient=*/\n            self.this_address(),\n            self.version(),\n            content,\n            secret_hash,\n            leaf_index,\n        );\n        let nullifier = compute_l1_to_l2_message_nullifier(message_hash, secret);\n\n        assert(\n            !self.nullifier_exists(nullifier, self.this_address()),\n            \"L1-to-L2 message is already nullified\",\n        );\n        assert(\n            self.l1_to_l2_msg_exists(message_hash, leaf_index),\n            \"Tried to consume nonexistent L1-to-L2 message\",\n        );\n\n        self.push_nullifier(nullifier);\n    }\n\n    pub fn message_portal(_self: &mut Self, recipient: EthAddress, content: Field) {\n        // Safety: AVM opcodes are constrained by the AVM itself\n        unsafe { send_l2_to_l1_msg(recipient, content) };\n    }\n\n    pub unconstrained fn call_public_function(\n        _self: &mut Self,\n        contract_address: AztecAddress,\n        function_selector: FunctionSelector,\n        args: [Field],\n        gas_opts: GasOpts,\n    ) -> [Field] {\n        let calldata = args.push_front(function_selector.to_field());\n\n        call(\n            gas_opts.l2_gas.unwrap_or(MAX_FIELD_VALUE),\n            gas_opts.da_gas.unwrap_or(MAX_FIELD_VALUE),\n            contract_address,\n            calldata,\n        );\n        // Use success_copy to determine whether the call succeeded\n        let success = success_copy();\n\n        let result_data = returndata_copy(0, returndata_size());\n        if !success {\n            // Rethrow the revert data.\n            avm_revert(result_data);\n        }\n        result_data\n    }\n\n    pub unconstrained fn static_call_public_function(\n        _self: &mut Self,\n        contract_address: AztecAddress,\n        function_selector: FunctionSelector,\n        args: [Field],\n        gas_opts: GasOpts,\n    ) -> [Field] {\n        let calldata = args.push_front(function_selector.to_field());\n\n        call_static(\n            gas_opts.l2_gas.unwrap_or(MAX_FIELD_VALUE),\n            gas_opts.da_gas.unwrap_or(MAX_FIELD_VALUE),\n            contract_address,\n            calldata,\n        );\n        // Use success_copy to determine whether the call succeeded\n        let success = success_copy();\n\n        let result_data = returndata_copy(0, returndata_size());\n        if !success {\n            // Rethrow the revert data.\n            avm_revert(result_data);\n        }\n        result_data\n    }\n\n    pub fn push_note_hash(_self: &mut Self, note_hash: Field) {\n        // Safety: AVM opcodes are constrained by the AVM itself\n        unsafe { emit_note_hash(note_hash) };\n    }\n    pub fn push_nullifier(_self: &mut Self, nullifier: Field) {\n        // Safety: AVM opcodes are constrained by the AVM itself\n        unsafe { emit_nullifier(nullifier) };\n    }\n\n    pub fn this_address(_self: Self) -> AztecAddress {\n        // Safety: AVM opcodes are constrained by the AVM itself\n        unsafe {\n            address()\n        }\n    }\n    pub fn msg_sender(_self: Self) -> AztecAddress {\n        // Safety: AVM opcodes are constrained by the AVM itself\n        unsafe {\n            sender()\n        }\n    }\n    pub fn selector(_self: Self) -> FunctionSelector {\n        // The selector is the first element of the calldata when calling a public function through dispatch.\n        // Safety: AVM opcodes are constrained by the AVM itself\n        let raw_selector: [Field; 1] = unsafe { calldata_copy(0, 1) };\n        FunctionSelector::from_field(raw_selector[0])\n    }\n    pub fn get_args_hash(mut self) -> Field {\n        if !self.args_hash.is_some() {\n            self.args_hash = Option::some((self.compute_args_hash)());\n        }\n\n        self.args_hash.unwrap_unchecked()\n    }\n    pub fn transaction_fee(_self: Self) -> Field {\n        // Safety: AVM opcodes are constrained by the AVM itself\n        unsafe {\n            transaction_fee()\n        }\n    }\n\n    pub fn chain_id(_self: Self) -> Field {\n        // Safety: AVM opcodes are constrained by the AVM itself\n        unsafe {\n            chain_id()\n        }\n    }\n    pub fn version(_self: Self) -> Field {\n        // Safety: AVM opcodes are constrained by the AVM itself\n        unsafe {\n            version()\n        }\n    }\n    pub fn block_number(_self: Self) -> Field {\n        // Safety: AVM opcodes are constrained by the AVM itself\n        unsafe {\n            block_number()\n        }\n    }\n    pub fn timestamp(_self: Self) -> u64 {\n        // Safety: AVM opcodes are constrained by the AVM itself\n        unsafe {\n            timestamp()\n        }\n    }\n    pub fn fee_per_l2_gas(_self: Self) -> Field {\n        // Safety: AVM opcodes are constrained by the AVM itself\n        unsafe {\n            fee_per_l2_gas()\n        }\n    }\n    pub fn fee_per_da_gas(_self: Self) -> Field {\n        // Safety: AVM opcodes are constrained by the AVM itself\n        unsafe {\n            fee_per_da_gas()\n        }\n    }\n\n    pub fn l2_gas_left(_self: Self) -> Field {\n        // Safety: AVM opcodes are constrained by the AVM itself\n        unsafe {\n            l2_gas_left()\n        }\n    }\n    pub fn da_gas_left(_self: Self) -> Field {\n        // Safety: AVM opcodes are constrained by the AVM itself\n        unsafe {\n            da_gas_left()\n        }\n    }\n    pub fn is_static_call(_self: Self) -> bool {\n        // Safety: AVM opcodes are constrained by the AVM itself\n        unsafe { is_static_call() } == 1\n    }\n\n    pub fn raw_storage_read<let N: u32>(_self: Self, storage_slot: Field) -> [Field; N] {\n        let mut out = [0; N];\n        for i in 0..N {\n            // Safety: AVM opcodes are constrained by the AVM itself\n            out[i] = unsafe { storage_read(storage_slot + i as Field) };\n        }\n        out\n    }\n\n    pub fn storage_read<T, let N: u32>(self, storage_slot: Field) -> T\n    where\n        T: Packable<N>,\n    {\n        T::unpack(self.raw_storage_read(storage_slot))\n    }\n\n    pub fn raw_storage_write<let N: u32>(_self: Self, storage_slot: Field, values: [Field; N]) {\n        for i in 0..N {\n            // Safety: AVM opcodes are constrained by the AVM itself\n            unsafe { storage_write(storage_slot + i as Field, values[i]) };\n        }\n    }\n\n    pub fn storage_write<T, let N: u32>(self, storage_slot: Field, value: T)\n    where\n        T: Packable<N>,\n    {\n        self.raw_storage_write(storage_slot, value.pack());\n    }\n}\n\n// Unconstrained opcode wrappers (do not use directly).\nunconstrained fn address() -> AztecAddress {\n    address_opcode()\n}\nunconstrained fn sender() -> AztecAddress {\n    sender_opcode()\n}\nunconstrained fn transaction_fee() -> Field {\n    transaction_fee_opcode()\n}\nunconstrained fn chain_id() -> Field {\n    chain_id_opcode()\n}\nunconstrained fn version() -> Field {\n    version_opcode()\n}\nunconstrained fn block_number() -> Field {\n    block_number_opcode()\n}\nunconstrained fn timestamp() -> u64 {\n    timestamp_opcode()\n}\nunconstrained fn fee_per_l2_gas() -> Field {\n    fee_per_l2_gas_opcode()\n}\nunconstrained fn fee_per_da_gas() -> Field {\n    fee_per_da_gas_opcode()\n}\nunconstrained fn l2_gas_left() -> Field {\n    l2_gas_left_opcode()\n}\nunconstrained fn da_gas_left() -> Field {\n    da_gas_left_opcode()\n}\nunconstrained fn is_static_call() -> Field {\n    is_static_call_opcode()\n}\nunconstrained fn note_hash_exists(note_hash: Field, leaf_index: Field) -> u1 {\n    note_hash_exists_opcode(note_hash, leaf_index)\n}\nunconstrained fn emit_note_hash(note_hash: Field) {\n    emit_note_hash_opcode(note_hash)\n}\nunconstrained fn nullifier_exists(nullifier: Field, address: Field) -> u1 {\n    nullifier_exists_opcode(nullifier, address)\n}\nunconstrained fn emit_nullifier(nullifier: Field) {\n    emit_nullifier_opcode(nullifier)\n}\nunconstrained fn emit_public_log(message: [Field]) {\n    emit_public_log_opcode(message)\n}\nunconstrained fn l1_to_l2_msg_exists(msg_hash: Field, msg_leaf_index: Field) -> u1 {\n    l1_to_l2_msg_exists_opcode(msg_hash, msg_leaf_index)\n}\nunconstrained fn send_l2_to_l1_msg(recipient: EthAddress, content: Field) {\n    send_l2_to_l1_msg_opcode(recipient, content)\n}\nunconstrained fn call(\n    l2_gas_allocation: Field,\n    da_gas_allocation: Field,\n    address: AztecAddress,\n    args: [Field],\n) {\n    call_opcode(l2_gas_allocation, da_gas_allocation, address, args)\n}\n\nunconstrained fn call_static(\n    l2_gas_allocation: Field,\n    da_gas_allocation: Field,\n    address: AztecAddress,\n    args: [Field],\n) {\n    call_static_opcode(l2_gas_allocation, da_gas_allocation, address, args)\n}\n\npub unconstrained fn calldata_copy<let N: u32>(cdoffset: u32, copy_size: u32) -> [Field; N] {\n    calldata_copy_opcode(cdoffset, copy_size)\n}\n\n// `success_copy` is placed immediately after the CALL opcode to get the success value\nunconstrained fn success_copy() -> bool {\n    success_copy_opcode()\n}\n\nunconstrained fn returndata_size() -> u32 {\n    returndata_size_opcode()\n}\n\nunconstrained fn returndata_copy(rdoffset: u32, copy_size: u32) -> [Field] {\n    returndata_copy_opcode(rdoffset, copy_size)\n}\n\npub unconstrained fn avm_return(returndata: [Field]) {\n    return_opcode(returndata)\n}\n\n// This opcode reverts using the exact data given. In general it should only be used\n// to do rethrows, where the revert data is the same as the original revert data.\n// For normal reverts, use Noir's `assert` which, on top of reverting, will also add\n// an error selector to the revert data.\nunconstrained fn avm_revert(revertdata: [Field]) {\n    revert_opcode(revertdata)\n}\n\nunconstrained fn storage_read(storage_slot: Field) -> Field {\n    storage_read_opcode(storage_slot)\n}\n\nunconstrained fn storage_write(storage_slot: Field, value: Field) {\n    storage_write_opcode(storage_slot, value);\n}\n\nimpl Empty for PublicContext {\n    fn empty() -> Self {\n        PublicContext::new(|| 0)\n    }\n}\n\n// AVM oracles (opcodes) follow, do not use directly.\n#[oracle(avmOpcodeAddress)]\nunconstrained fn address_opcode() -> AztecAddress {}\n\n#[oracle(avmOpcodeSender)]\nunconstrained fn sender_opcode() -> AztecAddress {}\n\n#[oracle(avmOpcodeTransactionFee)]\nunconstrained fn transaction_fee_opcode() -> Field {}\n\n#[oracle(avmOpcodeChainId)]\nunconstrained fn chain_id_opcode() -> Field {}\n\n#[oracle(avmOpcodeVersion)]\nunconstrained fn version_opcode() -> Field {}\n\n#[oracle(avmOpcodeBlockNumber)]\nunconstrained fn block_number_opcode() -> Field {}\n\n#[oracle(avmOpcodeTimestamp)]\nunconstrained fn timestamp_opcode() -> u64 {}\n\n#[oracle(avmOpcodeFeePerL2Gas)]\nunconstrained fn fee_per_l2_gas_opcode() -> Field {}\n\n#[oracle(avmOpcodeFeePerDaGas)]\nunconstrained fn fee_per_da_gas_opcode() -> Field {}\n\n#[oracle(avmOpcodeL2GasLeft)]\nunconstrained fn l2_gas_left_opcode() -> Field {}\n\n#[oracle(avmOpcodeDaGasLeft)]\nunconstrained fn da_gas_left_opcode() -> Field {}\n\n#[oracle(avmOpcodeIsStaticCall)]\nunconstrained fn is_static_call_opcode() -> Field {}\n\n#[oracle(avmOpcodeNoteHashExists)]\nunconstrained fn note_hash_exists_opcode(note_hash: Field, leaf_index: Field) -> u1 {}\n\n#[oracle(avmOpcodeEmitNoteHash)]\nunconstrained fn emit_note_hash_opcode(note_hash: Field) {}\n\n#[oracle(avmOpcodeNullifierExists)]\nunconstrained fn nullifier_exists_opcode(nullifier: Field, address: Field) -> u1 {}\n\n#[oracle(avmOpcodeEmitNullifier)]\nunconstrained fn emit_nullifier_opcode(nullifier: Field) {}\n\n// TODO(#11124): rename unencrypted to public in avm\n#[oracle(avmOpcodeEmitUnencryptedLog)]\nunconstrained fn emit_public_log_opcode(message: [Field]) {}\n\n#[oracle(avmOpcodeL1ToL2MsgExists)]\nunconstrained fn l1_to_l2_msg_exists_opcode(msg_hash: Field, msg_leaf_index: Field) -> u1 {}\n\n#[oracle(avmOpcodeSendL2ToL1Msg)]\nunconstrained fn send_l2_to_l1_msg_opcode(recipient: EthAddress, content: Field) {}\n\n#[oracle(avmOpcodeCalldataCopy)]\nunconstrained fn calldata_copy_opcode<let N: u32>(cdoffset: u32, copy_size: u32) -> [Field; N] {}\n\n#[oracle(avmOpcodeReturndataSize)]\nunconstrained fn returndata_size_opcode() -> u32 {}\n\n#[oracle(avmOpcodeReturndataCopy)]\nunconstrained fn returndata_copy_opcode(rdoffset: u32, copy_size: u32) -> [Field] {}\n\n#[oracle(avmOpcodeReturn)]\nunconstrained fn return_opcode(returndata: [Field]) {}\n\n// This opcode reverts using the exact data given. In general it should only be used\n// to do rethrows, where the revert data is the same as the original revert data.\n// For normal reverts, use Noir's `assert` which, on top of reverting, will also add\n// an error selector to the revert data.\n#[oracle(avmOpcodeRevert)]\nunconstrained fn revert_opcode(revertdata: [Field]) {}\n\n#[oracle(avmOpcodeCall)]\nunconstrained fn call_opcode(\n    l2_gas_allocation: Field,\n    da_gas_allocation: Field,\n    address: AztecAddress,\n    args: [Field],\n) {}\n\n#[oracle(avmOpcodeStaticCall)]\nunconstrained fn call_static_opcode(\n    l2_gas_allocation: Field,\n    da_gas_allocation: Field,\n    address: AztecAddress,\n    args: [Field],\n) {}\n\n#[oracle(avmOpcodeSuccessCopy)]\nunconstrained fn success_copy_opcode() -> bool {}\n\n#[oracle(avmOpcodeStorageRead)]\nunconstrained fn storage_read_opcode(storage_slot: Field) -> Field {}\n\n#[oracle(avmOpcodeStorageWrite)]\nunconstrained fn storage_write_opcode(storage_slot: Field, value: Field) {}\n"
    },
    "63": {
      "path": "/home/aztec-dev/aztec-packages/noir-projects/aztec-nr/aztec/src/context/utility_context.nr",
      "source": "use crate::oracle::{\n    execution::{get_block_number, get_chain_id, get_contract_address, get_version},\n    storage::storage_read,\n};\nuse dep::protocol_types::{address::AztecAddress, traits::Packable};\n\npub struct UtilityContext {\n    block_number: u32,\n    contract_address: AztecAddress,\n    version: Field,\n    chain_id: Field,\n}\n\nimpl UtilityContext {\n    pub unconstrained fn new() -> Self {\n        // We could call these oracles on the getters instead of at creation, which makes sense given that they might\n        // not even be accessed. However any performance gains are minimal, and we'd rather fail early if a user\n        // incorrectly attempts to create a UtilityContext in an environment in which these oracles are not\n        // available.\n        let block_number = get_block_number();\n        let contract_address = get_contract_address();\n        let chain_id = get_chain_id();\n        let version = get_version();\n        Self { block_number, contract_address, version, chain_id }\n    }\n\n    pub unconstrained fn at(contract_address: AztecAddress) -> Self {\n        let block_number = get_block_number();\n        let chain_id = get_chain_id();\n        let version = get_version();\n        Self { block_number, contract_address, version, chain_id }\n    }\n\n    pub unconstrained fn at_historical(contract_address: AztecAddress, block_number: u32) -> Self {\n        let chain_id = get_chain_id();\n        let version = get_version();\n        Self { block_number, contract_address, version, chain_id }\n    }\n\n    pub fn block_number(self) -> u32 {\n        self.block_number\n    }\n\n    pub fn this_address(self) -> AztecAddress {\n        self.contract_address\n    }\n\n    pub fn version(self) -> Field {\n        self.version\n    }\n\n    pub fn chain_id(self) -> Field {\n        self.chain_id\n    }\n\n    pub unconstrained fn raw_storage_read<let N: u32>(\n        self: Self,\n        storage_slot: Field,\n    ) -> [Field; N] {\n        storage_read(self.this_address(), storage_slot, self.block_number())\n    }\n\n    pub unconstrained fn storage_read<T, let N: u32>(self, storage_slot: Field) -> T\n    where\n        T: Packable<N>,\n    {\n        T::unpack(self.raw_storage_read(storage_slot))\n    }\n}\n"
    },
    "89": {
      "path": "/home/aztec-dev/aztec-packages/noir-projects/aztec-nr/aztec/src/macros/dispatch.nr",
      "source": "use super::utils::compute_fn_selector;\nuse std::panic;\n\n/// Returns an `fn public_dispatch(...)` function for the given module that's assumed to be an Aztec contract.\npub comptime fn generate_public_dispatch(m: Module) -> Quoted {\n    let functions = m.functions();\n    let functions =\n        functions.filter(|function: FunctionDefinition| function.has_named_attribute(\"public\"));\n\n    let unit = get_type::<()>();\n\n    let ifs = functions.map(|function: FunctionDefinition| {\n        let parameters = function.parameters();\n        let return_type = function.return_type();\n\n        let selector: Field = compute_fn_selector(function);\n\n        let mut parameters_size = 0;\n        for param in parameters {\n            parameters_size += size_in_fields(param.1);\n        }\n\n        let initial_read = if parameters.len() == 0 {\n            quote {}\n        } else {\n            // The initial calldata_copy offset is 1 to skip the Field selector\n            // The expected calldata is the serialization of\n            // - FunctionSelector: the selector of the function intended to dispatch\n            // - Parameters: the parameters of the function intended to dispatch\n            // That is, exactly what is expected for a call to the target function,\n            // but with a selector added at the beginning.\n            quote {\n                let input_calldata: [Field; $parameters_size] = dep::aztec::context::public_context::calldata_copy(1, $parameters_size);\n                let mut reader = dep::aztec::protocol_types::utils::reader::Reader::new(input_calldata);\n            }\n        };\n\n        let parameter_index = &mut 0;\n        let reads = parameters.map(|param: (Quoted, Type)| {\n            let parameter_index_value = *parameter_index;\n            let param_name = f\"arg{parameter_index_value}\".quoted_contents();\n            let param_type = param.1;\n            let read = quote {\n                let $param_name: $param_type = reader.read_struct(dep::aztec::protocol_types::traits::Deserialize::deserialize);\n            };\n            *parameter_index += 1;\n            quote { $read }\n        });\n        let read = reads.join(quote { });\n\n        let mut args = &[];\n        for parameter_index in 0..parameters.len() {\n            let param_name = f\"arg{parameter_index}\".quoted_contents();\n            args = args.push_back(quote { $param_name });\n        }\n\n        let args = args.join(quote { , });\n        // name of the function is assigned just before the call so debug metadata doesn't span most of this macro when figuring out where the call comes from.\n        let name = function.name();\n        let call = quote { $name($args) };\n\n        let return_code = if return_type == unit {\n            quote {\n                $call;\n                // Force early return.\n                dep::aztec::context::public_context::avm_return([]);\n            }\n        } else {\n            quote {\n                let return_value = dep::aztec::protocol_types::traits::Serialize::serialize($call);\n                dep::aztec::context::public_context::avm_return(return_value.as_slice());\n            }\n        };\n\n        let if_ = quote {\n            if selector == $selector {\n                $initial_read\n                $read\n                $return_code\n            }\n        };\n        if_\n    });\n\n    if ifs.len() == 0 {\n        // No dispatch function if there are no public functions\n        quote {}\n    } else {\n        let ifs = ifs.push_back(quote { panic(f\"Unknown selector {selector}\") });\n        let dispatch = ifs.join(quote {  });\n\n        let body = quote {\n            // We mark this as public because our whole system depends on public\n            // functions having this attribute. However, the public MACRO will\n            // handle the public_dispatch function specially and do nothing.\n            #[public]\n            pub unconstrained fn public_dispatch(selector: Field) {\n                $dispatch\n            }\n        };\n\n        body\n    }\n}\n\ncomptime fn size_in_fields(typ: Type) -> u32 {\n    let size = array_size_in_fields(typ);\n    let size = size.or_else(|| bool_size_in_fields(typ));\n    let size = size.or_else(|| constant_size_in_fields(typ));\n    let size = size.or_else(|| field_size_in_fields(typ));\n    let size = size.or_else(|| int_size_in_fields(typ));\n    let size = size.or_else(|| str_size_in_fields(typ));\n    let size = size.or_else(|| struct_size_in_fields(typ));\n    let size = size.or_else(|| tuple_size_in_fields(typ));\n    if size.is_some() {\n        size.unwrap()\n    } else {\n        panic(f\"Can't determine size in fields of {typ}\")\n    }\n}\n\ncomptime fn array_size_in_fields(typ: Type) -> Option<u32> {\n    typ.as_array().and_then(|typ: (Type, Type)| {\n        let (typ, element_size) = typ;\n        element_size.as_constant().map(|x: u32| x * size_in_fields(typ))\n    })\n}\n\ncomptime fn bool_size_in_fields(typ: Type) -> Option<u32> {\n    if typ.is_bool() {\n        Option::some(1)\n    } else {\n        Option::none()\n    }\n}\n\ncomptime fn field_size_in_fields(typ: Type) -> Option<u32> {\n    if typ.is_field() {\n        Option::some(1)\n    } else {\n        Option::none()\n    }\n}\n\ncomptime fn int_size_in_fields(typ: Type) -> Option<u32> {\n    if typ.as_integer().is_some() {\n        Option::some(1)\n    } else {\n        Option::none()\n    }\n}\n\ncomptime fn constant_size_in_fields(typ: Type) -> Option<u32> {\n    typ.as_constant()\n}\n\ncomptime fn str_size_in_fields(typ: Type) -> Option<u32> {\n    typ.as_str().map(|typ| size_in_fields(typ))\n}\n\ncomptime fn struct_size_in_fields(typ: Type) -> Option<u32> {\n    typ.as_data_type().map(|typ: (TypeDefinition, [Type])| {\n        let struct_type = typ.0;\n        let generics = typ.1;\n        let mut size = 0;\n        for field in struct_type.fields(generics) {\n            size += size_in_fields(field.1);\n        }\n        size\n    })\n}\n\ncomptime fn tuple_size_in_fields(typ: Type) -> Option<u32> {\n    typ.as_tuple().map(|types: [Type]| {\n        let mut size = 0;\n        for typ in types {\n            size += size_in_fields(typ);\n        }\n        size\n    })\n}\n\ncomptime fn get_type<T>() -> Type {\n    let t: T = std::mem::zeroed();\n    std::meta::type_of(t)\n}\n"
    },
    "96": {
      "path": "/home/aztec-dev/aztec-packages/noir-projects/aztec-nr/aztec/src/macros/functions/utils.nr",
      "source": "use crate::macros::{\n    functions::{abi_export::create_fn_abi_export, call_interface_stubs::stub_fn, stub_registry},\n    notes::NOTES,\n    utils::{\n        add_to_hasher, fn_has_noinitcheck, get_fn_visibility, is_fn_contract_library_method,\n        is_fn_initializer, is_fn_internal, is_fn_private, is_fn_public, is_fn_test, is_fn_utility,\n        is_fn_view, modify_fn_body, module_has_initializer, module_has_storage,\n    },\n};\nuse protocol_types::meta::generate_serialize_to_fields;\nuse std::meta::type_of;\n\npub(crate) comptime fn transform_private(f: FunctionDefinition) -> Quoted {\n    let fn_abi = create_fn_abi_export(f);\n    let fn_stub = stub_fn(f);\n    stub_registry::register(f.module(), fn_stub);\n\n    // If a function is further modified as unconstrained, we throw an error\n    if f.is_unconstrained() {\n        let name = f.name();\n        panic(\n            f\"Function {name} is annotated with #[private] but marked as unconstrained, remove unconstrained keyword\",\n        );\n    }\n\n    let module_has_initializer = module_has_initializer(f.module());\n    let module_has_storage = module_has_storage(f.module());\n\n    // Private functions undergo a lot of transformations from their Aztec.nr form into a circuit that can be fed to the\n    // Private Kernel Circuit.\n    // First we change the function signature so that it also receives `PrivateContextInputs`, which contain information\n    // about the execution context (e.g. the caller).\n    let original_params = f.parameters();\n    f.set_parameters(&[(\n        quote { inputs },\n        quote { crate::context::inputs::private_context_inputs::PrivateContextInputs }.as_type(),\n    )]\n        .append(original_params));\n\n    let mut body = f.body().as_block().unwrap();\n\n    // The original params are hashed and passed to the `context` object, so that the kernel can verify we've received\n    // the correct values.\n    // TODO: Optimize args_hasher for small number of arguments\n    let args_hasher_name = quote { args_hasher };\n    let args_hasher = original_params.fold(\n        quote {\n            let mut $args_hasher_name = dep::aztec::hash::ArgsHasher::new();\n        },\n        |args_hasher, param: (Quoted, Type)| {\n            let (name, typ) = param;\n            let appended_arg = add_to_hasher(args_hasher_name, name, typ);\n            quote {\n                $args_hasher\n                $appended_arg\n            }\n        },\n    );\n\n    let context_creation = quote {\n        let mut context = dep::aztec::context::private_context::PrivateContext::new(inputs, dep::aztec::protocol_types::traits::Hash::hash($args_hasher_name));\n    };\n\n    // Modifications introduced by the different marker attributes.\n    let internal_check = if is_fn_internal(f) {\n        create_internal_check(f)\n    } else {\n        quote {}\n    };\n\n    let view_check = if is_fn_view(f) {\n        create_view_check(f)\n    } else {\n        quote {}\n    };\n\n    let (assert_initializer, mark_as_initialized) = if is_fn_initializer(f) {\n        (create_assert_correct_initializer_args(f), create_mark_as_initialized(f))\n    } else {\n        (quote {}, quote {})\n    };\n\n    let storage_init = if module_has_storage {\n        quote {\n            // Some functions don't access storage, but it'd be quite difficult to only inject this variable if it is\n            // referenced. We instead ignore 'unused variable' warnings for it.\n            #[allow(unused_variables)]\n            let storage = Storage::init(&mut context);\n        }\n    } else {\n        quote {}\n    };\n\n    // Initialization checks are not included in contracts that don't have initializers.\n    let init_check = if module_has_initializer & !is_fn_initializer(f) & !fn_has_noinitcheck(f) {\n        create_init_check(f)\n    } else {\n        quote {}\n    };\n\n    // All private functions perform message discovery, since they may need to access notes. This is slightly\n    // inefficient and could be improved by only doing it once we actually attempt to read any.\n    let message_discovery_call = if NOTES.len() > 0 {\n        create_message_discovery_call()\n    } else {\n        quote {}\n    };\n\n    // Finally, we need to change the return type to be `PrivateCircuitPublicInputs`, which is what the Private Kernel\n    // circuit expects.\n    let return_value_var_name = quote { macro__returned__values };\n\n    let return_value_type = f.return_type();\n    let return_value = if body.len() == 0 {\n        quote {}\n    } else if return_value_type != type_of(()) {\n        // The original return value is passed to a second args hasher which the context receives.\n        let (body_without_return, last_body_expr) = body.pop_back();\n        let return_value = last_body_expr.quoted();\n        let return_value_assignment =\n            quote { let $return_value_var_name: $return_value_type = $return_value; };\n        let return_hasher_name = quote { return_hasher };\n        let return_value_into_hasher =\n            add_to_hasher(return_hasher_name, return_value_var_name, return_value_type);\n\n        body = body_without_return;\n\n        quote {\n            let mut $return_hasher_name = dep::aztec::hash::ArgsHasher::new();\n            $return_value_assignment\n            $return_value_into_hasher\n            context.set_return_hash($return_hasher_name);\n        }\n    } else {\n        let (body_without_return, last_body_expr) = body.pop_back();\n        if !last_body_expr.has_semicolon()\n            & last_body_expr.as_for().is_none()\n            & last_body_expr.as_assert().is_none()\n            & last_body_expr.as_for_range().is_none()\n            & last_body_expr.as_assert_eq().is_none()\n            & last_body_expr.as_let().is_none() {\n            let unused_return_value_name = f\"_{return_value_var_name}\".quoted_contents();\n            body = body_without_return.push_back(\n                quote { let $unused_return_value_name = $last_body_expr; }.as_expr().unwrap(),\n            );\n        }\n        quote {}\n    };\n\n    let context_finish = quote { context.finish() };\n\n    let to_prepend = quote {\n        $args_hasher\n        $context_creation\n        $assert_initializer\n        $init_check\n        $internal_check\n        $view_check\n        $storage_init\n        $message_discovery_call\n    };\n\n    let to_append = quote {\n        $return_value\n        $mark_as_initialized\n        $context_finish\n    };\n    let modified_body = modify_fn_body(body, to_prepend, to_append);\n    f.set_body(modified_body);\n    f.set_return_type(\n        quote { dep::protocol_types::abis::private_circuit_public_inputs::PrivateCircuitPublicInputs }\n            .as_type(),\n    );\n    f.set_return_data();\n\n    fn_abi\n}\n\npub(crate) comptime fn transform_public(f: FunctionDefinition) -> Quoted {\n    let fn_abi = create_fn_abi_export(f);\n    let fn_stub = stub_fn(f);\n    stub_registry::register(f.module(), fn_stub);\n\n    // If a function is further modified as unconstrained, we throw an error\n    if f.is_unconstrained() {\n        let name = f.name();\n        panic(\n            f\"Function {name} is annotated with #[public] but marked as unconstrained, remove unconstrained keyword\",\n        );\n    }\n\n    let module_has_initializer = module_has_initializer(f.module());\n    let module_has_storage = module_has_storage(f.module());\n\n    // Public functions undergo a lot of transformations from their Aztec.nr form.\n    let original_params = f.parameters();\n    let args_len = original_params\n        .map(|(name, typ): (Quoted, Type)| {\n            generate_serialize_to_fields(name, typ, false).0.len()\n        })\n        .fold(0, |acc: u32, val: u32| acc + val);\n\n    // Unlike in the private case, in public the `context` does not need to receive the hash of the original params.\n    let context_creation = quote {\n        let mut context = dep::aztec::context::public_context::PublicContext::new(|| {\n        // We start from 1 because we skip the selector for the dispatch function.\n        let serialized_args : [Field; $args_len] = dep::aztec::context::public_context::calldata_copy(1, $args_len);\n        dep::aztec::hash::hash_args_array(serialized_args)\n        });\n    };\n\n    // Modifications introduced by the different marker attributes.\n    let internal_check = if is_fn_internal(f) {\n        create_internal_check(f)\n    } else {\n        quote {}\n    };\n\n    let view_check = if is_fn_view(f) {\n        create_view_check(f)\n    } else {\n        quote {}\n    };\n\n    let (assert_initializer, mark_as_initialized) = if is_fn_initializer(f) {\n        (create_assert_correct_initializer_args(f), create_mark_as_initialized(f))\n    } else {\n        (quote {}, quote {})\n    };\n\n    let storage_init = if module_has_storage {\n        // Some functions don't access storage, but it'd be quite difficult to only inject this variable if it is\n        // referenced. We instead ignore 'unused variable' warnings for it.\n        quote {\n            #[allow(unused_variables)]\n            let storage = Storage::init(&mut context);\n        }\n    } else {\n        quote {}\n    };\n\n    // Initialization checks are not included in contracts that don't have initializers.\n    let init_check = if module_has_initializer & !fn_has_noinitcheck(f) & !is_fn_initializer(f) {\n        create_init_check(f)\n    } else {\n        quote {}\n    };\n\n    let to_prepend = quote {\n        $context_creation\n        $assert_initializer\n        $init_check\n        $internal_check\n        $view_check\n        $storage_init\n    };\n\n    let to_append = quote {\n        $mark_as_initialized\n    };\n\n    let body = f.body().as_block().unwrap();\n    let modified_body = modify_fn_body(body, to_prepend, to_append);\n    f.set_body(modified_body);\n\n    // All public functions are automatically made unconstrained, even if they were not marked as such. This is because\n    // instead of compiling into a circuit, they will compile to bytecode that will be later transpiled into AVM\n    // bytecode.\n    f.set_unconstrained(true);\n    f.set_return_public(true);\n\n    fn_abi\n}\n\npub(crate) comptime fn transform_utility(f: FunctionDefinition) {\n    // Check if function is marked as unconstrained\n    if !f.is_unconstrained() {\n        let name = f.name();\n        panic(\n            f\"Function {name} is annotated with #[utility] but not marked as unconstrained, add unconstrained keyword\",\n        );\n    }\n\n    // Create utility context\n    let context_creation =\n        quote { let mut context = dep::aztec::context::utility_context::UtilityContext::new(); };\n    let module_has_storage = module_has_storage(f.module());\n\n    // Initialize Storage if module has storage\n    let storage_init = if module_has_storage {\n        quote {\n            // Some functions don't access storage, but it'd be quite difficult to only inject this variable if it is\n            // referenced. We instead ignore 'unused variable' warnings for it.\n            #[allow(unused_variables)]\n            let storage = Storage::init(context);\n        }\n    } else {\n        quote {}\n    };\n\n    // All utility functions perform message discovery, since they may need to access private notes that would be\n    // found during this process. This is slightly inefficient and could be improved by only doing it once we actually\n    // attempt to read any.\n    let message_discovery_call = if NOTES.len() > 0 {\n        create_message_discovery_call()\n    } else {\n        quote {}\n    };\n\n    // Inject context creation, storage initialization, and message discovery call at the beginning of the function\n    // body.\n    let to_prepend = quote {\n        $context_creation\n        $storage_init\n        $message_discovery_call\n    };\n    let body = f.body().as_block().unwrap();\n    let modified_body = modify_fn_body(body, to_prepend, quote {});\n    f.set_body(modified_body);\n\n    f.set_return_public(true);\n}\n\ncomptime fn create_internal_check(f: FunctionDefinition) -> Quoted {\n    let name = f.name();\n    let assertion_message = f\"Function {name} can only be called internally\";\n    quote { assert(context.msg_sender() == context.this_address(), $assertion_message); }\n}\n\ncomptime fn create_view_check(f: FunctionDefinition) -> Quoted {\n    let name = f.name();\n    let assertion_message = f\"Function {name} can only be called statically\";\n    if is_fn_private(f) {\n        // Here `context` is of type context::PrivateContext\n        quote { assert(context.inputs.call_context.is_static_call == true, $assertion_message); }\n    } else {\n        // Here `context` is of type context::PublicContext\n        quote { assert(context.is_static_call(), $assertion_message); }\n    }\n}\n\ncomptime fn create_assert_correct_initializer_args(f: FunctionDefinition) -> Quoted {\n    let fn_visibility = get_fn_visibility(f);\n    f\"dep::aztec::macros::functions::initialization_utils::assert_initialization_matches_address_preimage_{fn_visibility}(context);\"\n        .quoted_contents()\n}\n\ncomptime fn create_mark_as_initialized(f: FunctionDefinition) -> Quoted {\n    let fn_visibility = get_fn_visibility(f);\n    f\"dep::aztec::macros::functions::initialization_utils::mark_as_initialized_{fn_visibility}(&mut context);\"\n        .quoted_contents()\n}\n\ncomptime fn create_init_check(f: FunctionDefinition) -> Quoted {\n    let fn_visibility = get_fn_visibility(f);\n    f\"dep::aztec::macros::functions::initialization_utils::assert_is_initialized_{fn_visibility}(&mut context);\"\n        .quoted_contents()\n}\n\n/// Injects a call to `aztec::messages::discovery::discover_new_messages`, causing for new notes to be added to PXE and made\n/// available for the current execution.\npub(crate) comptime fn create_message_discovery_call() -> Quoted {\n    quote {\n        /// Safety: message discovery returns nothing and is performed solely for its side-effects. It is therefore\n        /// always safe to call.\n        unsafe {\n            dep::aztec::messages::discovery::discover_new_messages(\n                context.this_address(),\n                _compute_note_hash_and_nullifier,\n            );\n        };\n    }\n}\n\n/// Checks if each function in the module is marked with either #[private], #[public], #[utility],\n/// #[contract_library_method], or #[test]. Non-macroified functions are not allowed in contracts.\npub(crate) comptime fn check_each_fn_macroified(m: Module) {\n    for f in m.functions() {\n        let name = f.name();\n        if !is_fn_private(f)\n            & !is_fn_public(f)\n            & !is_fn_utility(f)\n            & !is_fn_contract_library_method(f)\n            & !is_fn_test(f) {\n            panic(\n                f\"Function {name} must be marked as either #[private], #[public], #[utility], #[contract_library_method], or #[test]\",\n            );\n        }\n    }\n}\n"
    },
    "99": {
      "path": "/home/aztec-dev/aztec-packages/noir-projects/aztec-nr/aztec/src/macros/storage.nr",
      "source": "use poseidon::poseidon2::Poseidon2Hasher;\nuse std::{collections::umap::UHashMap, hash::BuildHasherDefault};\n\nuse super::utils::AsStrQuote;\nuse super::utils::get_storage_size;\nuse super::utils::is_note;\n\n/// Stores a map from a module to the name of the struct that describes its storage layout.\n/// This is then used when generating a `storage_layout()` getter on the contract struct.\npub comptime mut global STORAGE_LAYOUT_NAME: UHashMap<Module, Quoted, BuildHasherDefault<Poseidon2Hasher>> =\n    UHashMap::default();\n\n/// Marks a struct as the one describing the storage layout of a contract. Only a single struct in the entire contract\n/// should have this macro (or `storage_no_init`) applied to it.\n/// The contract's storage is accessed via the `storage` variable, which will will automatically be made available in\n/// all functions as an instance of the struct this macro was applied to.\npub comptime fn storage(s: TypeDefinition) -> Quoted {\n    // This macro performs three things:\n    //  - it marks the contract as having storage, so that `macros::utils::module_has_storage` will return true and\n    //    functions will have the storage variable injected and initialized via the `init` function.\n    //  - it implements said `init` function by allocating appropriate storage slots to each state variable.\n    //  - it exposes the storage layout by creating a `StorageLayout` struct that is exposed via the `abi(storage)`\n    //    macro.\n    let mut slot: u32 = 1;\n    let mut storage_vars_constructors = &[];\n    let mut storage_layout_fields = &[];\n    let mut storage_layout_constructors = &[];\n\n    // TODO(#8658): uncomment the code below to inject the Context type parameter.\n    //let mut new_storage_fields = &[];\n    //let context_generic = s.add_generic(\"Context\");\n    for field in s.fields_as_written() {\n        // FIXME: This doesn't handle field types with generics\n        let (name, typ) = field;\n        let (storage_field_constructor, storage_size) =\n            generate_storage_field_constructor(typ, quote { $slot }, false);\n        storage_vars_constructors =\n            storage_vars_constructors.push_back(quote { $name: $storage_field_constructor });\n        // We have `Storable` in a separate `.nr` file instead of defining it in the last quote of this function\n        // because that way a dev gets a more reasonable error if he defines a struct with the same name in\n        // a contract.\n        storage_layout_fields =\n            storage_layout_fields.push_back(quote { pub $name: dep::aztec::prelude::Storable });\n        storage_layout_constructors = storage_layout_constructors.push_back(\n            quote { $name: dep::aztec::prelude::Storable { slot: $slot } },\n        );\n        //let with_context_generic = add_context_generic(typ, context_generic);\n        //println(with_context_generic);\n        //new_storage_fields = new_storage_fields.push_back((name,  with_context_generic ));\n        slot += storage_size;\n    }\n\n    //s.set_fields(new_storage_fields);\n    let storage_vars_constructors = storage_vars_constructors.join(quote {,});\n    let storage_impl = quote {\n        impl<Context> Storage<Context> {\n            fn init(context: Context) -> Self {\n                Self {\n                    $storage_vars_constructors\n                }\n            }\n        }\n    };\n\n    let storage_layout_fields = storage_layout_fields.join(quote {,});\n    let storage_layout_constructors = storage_layout_constructors.join(quote {,});\n\n    let module = s.module();\n    let module_name = module.name();\n    let storage_layout_name = f\"STORAGE_LAYOUT_{module_name}\".quoted_contents();\n    let (module_name_str, module_name_len) = module_name.as_str_quote();\n    STORAGE_LAYOUT_NAME.insert(module, storage_layout_name);\n\n    quote {\n        $storage_impl\n\n        pub struct StorageLayoutFields {\n            $storage_layout_fields\n        }\n\n        pub struct StorageLayout<let N: u32> {\n            pub contract_name: str<N>,\n            pub fields: StorageLayoutFields\n        }\n\n        #[abi(storage)]\n        pub global $storage_layout_name: StorageLayout<$module_name_len> = StorageLayout {\n            contract_name: $module_name_str,\n            fields: StorageLayoutFields { $storage_layout_constructors }\n        };\n    }\n}\n\n/// Same as `storage`, except the user is in charge of providing an implementation of the `init` constructor function\n/// with signature `fn init<Context>(context: Context) -> Self`, which allows for manual control of storage slot\n/// allocation. Similarly, no `StorageLayout` struct will be created.\n/// Only a single struct in the entire contract should have this macro (or `storage`) applied to it.\npub comptime fn storage_no_init(_s: TypeDefinition) {\n    // All `storage` does is provide the `init` implementation, so we don't need to do anything here. Applying this\n    // macro however will cause for `macros::utils::module_has_storage` to return true, resulting in the injection of\n    // the `storage` variable.\n}\n\n/// Returns the expression required to initialize a state variable with a given slot, along with its serialization size,\n/// i.e. how many contiguous storage slots the variable requires.\ncomptime fn generate_storage_field_constructor(\n    typ: Type,\n    slot: Quoted,\n    parent_is_map: bool,\n) -> (Quoted, u32) {\n    assert(\n        typ.as_data_type().is_some(),\n        \"Storage containers must be generic structs of the form `Container<_, Context>`, or Map<Key, _, Context>\",\n    );\n    let (container_struct, generics) = typ.as_data_type().unwrap();\n    let struct_name = container_struct.name();\n\n    if is_storage_map(typ) {\n        // Map state variables recursively initialize their contents - this includes nested maps.\n        let (value_constructor, _) =\n            generate_storage_field_constructor(generics[1], quote { slot }, true);\n        (quote { $struct_name::new(context, $slot, | context, slot | { $value_constructor }) }, 1)\n    } else {\n        let storage_size = if parent_is_map {\n            // Variables inside a map do not require contiguous slots since the map slot derivation is assumed to result\n            // in slots very far away from one another.\n            1\n        } else {\n            let (_, container_struct_generics) = typ.as_data_type().unwrap();\n            let stored_struct = container_struct_generics[0];\n\n            if is_note(stored_struct) {\n                // Private notes always occupy a single slot, since the slot is only used as a state variable\n                // identifier.\n                1\n            } else {\n                get_storage_size(typ)\n            }\n        };\n\n        // We assume below that all state variables implement `fn new<Context>(context: Context, slot: Field) -> Self`.\n        (quote { $struct_name::new(context, $slot)}, storage_size)\n    }\n}\n\n/// Returns true if `typ` is `state_vars::map::Map`.\ncomptime fn is_storage_map(typ: Type) -> bool {\n    if typ.as_data_type().is_some() {\n        let (def, generics) = typ.as_data_type().unwrap();\n        let maybe_map = if (def.name() == quote { Map }) & (generics.len() == 3) {\n            let maybe_key = generics[0];\n            let maybe_value = generics[1];\n            let maybe_context = generics[2];\n            quote { crate::state_vars::map::Map<$maybe_key, $maybe_value, $maybe_context> }.as_type()\n        } else {\n            quote {()}.as_type()\n        };\n        typ == maybe_map\n    } else {\n        false\n    }\n}\n\ncomptime fn add_context_generic(typ: Type, context_generic: Type) -> Type {\n    let (def, mut generics) = typ.as_data_type().expect(\n        f\"Storage containers must be generic structs of the form `Container<..., Context>`\",\n    );\n    let name = def.name();\n\n    if is_storage_map(typ) {\n        generics[generics.len() - 2] = add_context_generic(generics[1], context_generic);\n        generics[generics.len() - 1] = context_generic;\n    } else {\n        generics[generics.len() - 1] = context_generic;\n    }\n\n    let generics = generics.map(|typ: Type| quote {$typ}).join(quote {,});\n    quote { $name<$generics> }.as_type()\n}\n"
    }
  }
}
